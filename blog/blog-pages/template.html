<!DOCTYPE html>

<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Home</title>

    <link rel="stylesheet" href="../../static/css/blog-page.min.css">
</head>

<body>
    <div class="scan-lines">
        <div></div>
    </div>
    <div class="header-container">
        <header>
            <a class='header-logo' href="/">Achraf Bougadre</a>
            <nav>
                <a href="/">Home</a>
                <!-- <a href="blog/">Blog</a> -->
                <!-- <a href="#">Projects</a> -->
                <a href="static/cv/RESUME_ACHRAF_BOUGADRE.pdf" target="_blank">Resume</a>
            </nav>
        </header>
    </div>
    <main>

        <d-title>
            <h1>Understanding RL Vision</h1>
            <p>With diverse environments, we can analyze, diagnose and edit deep reinforcement learning models using
                attribution.</p>
        </d-title>
        <d-article>

            <d-contents>
                <nav class="l-text figcaption">
                    <h3>Contents</h3>
                    <div><a href="#introduction">Introduction</a></div>
                    <div><a href="#coinrun">Our CoinRun model</a></div>
                    <div><a href="#analysis">Model analysis</a></div>
                    <ul>
                        <li><a href="#dissecting-failure">Dissecting failure</a></li>
                        <li><a href="#hallucinations">Hallucinations</a></li>
                        <li><a href="#model-editing">Model editing</a></li>
                    </ul>
                    <div><a href="#diversity-hypothesis">The diversity hypothesis</a></div>
                    <div><a href="#feature-visualization">Feature visualization</a></div>
                    <div><a href="#attribution">Attribution</a></div>
                    <div><a href="#questions">Questions for further research</a></div>
                </nav>
            </d-contents>

            <div>
                <p id="introduction">
                    In this article, we apply interpretability techniques to a reinforcement learning (RL) model trained
                    to play the video game CoinRun <d-cite key="coinrunpaper"></d-cite>. Using attribution <d-cite
                        key="attribution1,attribution2,attribution3,gradcam,attribution4,attribution5,attribution6,integratedgradients">
                    </d-cite> combined with dimensionality reduction as in <d-cite key="buildingblocks"></d-cite>, we
                    build an interface for exploring the objects detected by the model, and how they influence its value
                    function and policy. We leverage this interface in several ways.
                </p>
                <ul>
                    <li><b><a href="#dissecting-failure">Dissecting failure</a>.</b> We perform a step-by-step analysis
                        of the agent’s behavior in cases where it failed to achieve the maximum reward, allowing us to
                        understand what went wrong, and why. For example, one case of failure was caused by an obstacle
                        being temporarily obscured from view.</li>
                    <li><b><a href="#hallucinations">Hallucinations</a>.</b> We find situations when the model
                        “hallucinated” a feature not present in the observation, thereby explaining inaccuracies in the
                        model’s value function. These were brief enough that they did not affect the agent’s behavior.
                    </li>
                    <li><b><a href="#model-editing">Model editing</a>.</b> We hand-edit the weights of the model to
                        blind the agent to certain hazards, without otherwise changing the agent’s behavior. We verify
                        the effects of these edits by checking which hazards cause the new agents to fail. Such editing
                        is only made possible by our previous analysis, and thus provides a quantitative validation of
                        this analysis.</li>
                </ul>
                <p>
                    Our results depend on levels in CoinRun being procedurally-generated, leading us to formulate a
                    <span style="font-style: italic;"><a href="#diversity-hypothesis">diversity hypothesis</a></span>
                    for interpretability. If it is correct, then we can expect RL models to become more interpretable as
                    the environments they are trained on become more diverse. We provide evidence for our hypothesis by
                    measuring the relationship between interpretability and generalization.
                </p>
                <p>
                    Finally, we provide a thorough <a href="#feature-visualization">investigation</a> of several
                    interpretability techniques in the context of RL vision, and pose a number of <a
                        href="#questions">questions</a> for further research.
                </p>
            </div>
            <h2 id="coinrun">Our CoinRun model</h2>
            <p>
                CoinRun is a side-scrolling platformer in which the agent must dodge enemies and other traps and collect
                the coin at the end of the level.
            </p>
            <p>
                CoinRun is procedurally-generated, meaning that each new level encountered by the agent is randomly
                generated from scratch. This incentivizes the model to learn how to spot the different kinds of objects
                in the game, since it cannot get away with simply memorizing a small number of specific trajectories
                <d-cite key="procgen"></d-cite>.<d-footnote id="d-footnote-1">We use the original version of CoinRun
                    <d-cite key="coinrunpaper"></d-cite>, not the version from Procgen Benchmark <d-cite key="procgen">
                    </d-cite>, which is slightly different. To play CoinRun yourself, please follow the instructions <a
                        href="https://github.com/openai/coinrun">here</a>.
                </d-footnote>
            </p>
            <p>
                Here are some examples of the objects used, along with walls and floors, to generate CoinRun levels.
            </p>
            <p>
                There are 9 actions available to the agent in CoinRun:
            </p>
            <p>
                We trained a convolutional neural network on CoinRun for around 2 billion timesteps, using PPO <d-cite
                    key="ppo"></d-cite>, an actor-critic algorithm.<d-footnote id="d-footnote-4">We used the standard
                    PPO hyperparameters for CoinRun <d-cite key="coinrunpaper"></d-cite>, except that we used twice as
                    many copies of the environment per worker and twice and many workers. The effect of these changes
                    was to increase the effective batch size, which seemed to be necessary to reach the same performance
                    with our smaller architecture.</d-footnote> The architecture of our network is described in <a
                    href="#architecture">Appendix C</a>. We used a non-recurrent network, to avoid any need to visualize
                multiple frames at once. Thus our model observes a single downsampled 64x64 image, and outputs a value
                function (an estimate of the total future time-discounted reward) and a policy (a probability
                distribution over the actions, from which the next action is sampled).
            </p>
            <p>
                Since the only available reward is a fixed bonus for collecting the coin, the value function estimates
                the time-discounted<d-footnote id="d-footnote-5">We use a discount rate of 0.999 per timestep.
                </d-footnote> probability that the agent will successfully complete the level.
            </p>
            <h2 id="analysis">Model analysis</h2>
            <p>
                Having trained a strong RL agent, we were curious to see what it had learned. Following <d-cite
                    key="buildingblocks"></d-cite>, we developed an interface for examining trajectories of the agent
                playing the game. This incorporates attribution from a hidden layer that recognizes objects, which
                serves to highlight objects that positively or negatively influence a particular network output. By
                applying dimensionality reduction, we obtain attribution vectors whose components correspond to
                different types of object, which we indicate using different colors.
            </p>
            <p id="interface">
                Here is our interface for a typical trajectory, with the value function as the network output. It
                reveals the model using obstacles, coins, enemies and more to compute the value function.
            </p>
            <h3 id="dissecting-failure">Dissecting failure</h3>
            <p>
                Our fully-trained model fails to complete around 1 in every 200 levels. We explored a few of these
                failures using our interface, and found that we were usually able to understand why they occurred.
            </p>
            <p>
                The failure often boils down to the fact that the model has no memory, and must therefore choose its
                action based only on the current observation. It is also common for some unlucky sampling of actions
                from the agent’s policy to be partly responsible.
            </p>
            <p>
                Here are some cherry-picked examples of failures, carefully analyzed step-by-step.
            </p>
            <table style="margin-top: 1em; margin-bottom: 1em;">
                <tbody>
                    <tr>
                        <td style="width: 50%; vertical-align: top;">
                            <label id="interface-failure-obscured-label"
                                style="color: black; --darkreader-inline-color: #e8e6e3;"
                                data-darkreader-inline-color="">
                                <b><input type="radio" name="interface-failure-options" checked=""
                                        id="interface-failure-obscured-option"> Buzzsaw obstacle obscured by enemy</b>
                            </label><br>
                            <label id="interface-failure-down-label"
                                style="color: lightgray; --darkreader-inline-color: #ccc8c1;"
                                data-darkreader-inline-color="">
                                <b><input type="radio" name="interface-failure-options"
                                        id="interface-failure-down-option"> Stepping down to avoid jumping</b>
                            </label><br>
                            <label id="interface-failure-offscreen-label"
                                style="color: lightgray; --darkreader-inline-color: #ccc8c1;"
                                data-darkreader-inline-color="">
                                <b><input type="radio" name="interface-failure-options"
                                        id="interface-failure-offscreen-option"> Landing platform moving off-screen</b>
                            </label>
                        </td>
                        <td style="vertical-align: top;">
                            <div style="min-height: 7.5em;">
                                <div style="display: block;" id="interface-failure-obscured-text">
                                    The agent moves too far to the right while in mid-air as a result of a buzzsaw
                                    obstacle being temporarily hidden from view by a moving enemy. The buzzsaw comes
                                    back into view, but too late to avoid a collision.
                                </div>
                                <div style="display: none;" id="interface-failure-down-text">
                                    The agent presses down in a bid to delay a jump. This causes the agent to
                                    inadvertently step down from a box and onto an enemy.
                                </div>
                                <div style="display: none;" id="interface-failure-offscreen-text">
                                    The agent fails to move far enough to the right while in mid-air, as a result of the
                                    platform where it was intending to land moving below the field of view.
                                </div>
                            </div>
                        </td>
                    </tr>
                </tbody>
            </table>
            <div style="display: flex; flex-flow: row; height: 116px;">
                <div>
                    <div style="display: flex; flex-flow: row;">
                        <div style="display: inline-block; margin-right:3px;">
                            <button id="interface-failure-previous" class="interface-failure-step-button" disabled=""
                                style="cursor: auto;">Prev</button><br>
                            <button id="interface-failure-start" class="interface-failure-step-button">Start</button>
                        </div>
                        <button id="interface-failure-play-pause-button" class="play-pause-button">
                            <span id="interface-failure-play-pause-span">►</span>
                        </button>
                        <div style="display: inline-block; margin-left:3px;">
                            <button id="interface-failure-next" class="interface-failure-step-button"
                                style="cursor: pointer;">Next</button><br>
                            <button id="interface-failure-end" class="interface-failure-step-button">End</button>
                        </div>
                        <br>
                    </div>
                    <span id="interface-failure-position">Timestep <b>1</b> of <b>18</b></span>
                </div>
                <div id="interface-failure-description" style="position: relative; height: 115px;">
                    <div id="interface-failure-description-obscured-0"
                        style="visibility: visible; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 1</b>: The agent moves right, invited by the unoccupied floor (<span
                            style="color: rgb(0, 255, 255); font-weight: 900; --darkreader-inline-color: #1affff;"
                            data-darkreader-inline-color="">•</span> <span
                            style="color: rgb(0, 78, 255); font-weight: 900; --darkreader-inline-color: #3395ff;"
                            data-darkreader-inline-color="">•</span>) in front of it.
                    </div>
                    <div id="interface-failure-description-obscured-1"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 2</b>: The agent prepares to jump, seeing the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) up ahead.
                    </div>
                    <div id="interface-failure-description-obscured-2"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 3</b>: The agent jumps by releasing up, analyzing something (◦) on the wall. (The
                        "residual" feature can be triggered by a number of different objects, and can be viewed by
                        hovering over the last legend item.)
                    </div>
                    <div id="interface-failure-description-obscured-3"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 4–6</b>: The agent is in mid-air, trying to control its horizontal motion. Its
                        policy has higher entropy as its actions matter less at the start of a jump (due to the entropy
                        bonus used in PPO).
                    </div>
                    <div id="interface-failure-description-obscured-4"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 4–6</b>: The agent is in mid-air, trying to control its horizontal motion. Its
                        policy has higher entropy as its actions matter less at the start of a jump (due to the entropy
                        bonus used in PPO).
                    </div>
                    <div id="interface-failure-description-obscured-5"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 4–6</b>: The agent is in mid-air, trying to control its horizontal motion. Its
                        policy has higher entropy as its actions matter less at the start of a jump (due to the entropy
                        bonus used in PPO).
                    </div>
                    <div id="interface-failure-description-obscured-6"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 7–8</b>: The agent moves right to be able to reach the top of the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>), though it is slightly discouraged from doing so
                        by the prescence of the enemy moving right (<span
                            style="color: rgb(0, 255, 78); font-weight: 900; --darkreader-inline-color: #1aff60;"
                            data-darkreader-inline-color="">•</span>).
                    </div>
                    <div id="interface-failure-description-obscured-7"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 7–8</b>: The agent moves right to be able to reach the top of the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>), though it is slightly discouraged from doing so
                        by the prescence of the enemy moving right (<span
                            style="color: rgb(0, 255, 78); font-weight: 900; --darkreader-inline-color: #1aff60;"
                            data-darkreader-inline-color="">•</span>).
                    </div>
                    <div id="interface-failure-description-obscured-8"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: Having adjusted its horizontal motion, the agent returns to a policy with
                        higher entropy. It is paying attention to the enemy moving right (<span
                            style="color: rgb(0, 255, 78); font-weight: 900; --darkreader-inline-color: #1aff60;"
                            data-darkreader-inline-color="">•</span>), which it is on track to avoid, but it cannot see
                        the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) obscured from view behind it. With some bad luck,
                        the agent happens to move right at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-obscured-9"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: Having adjusted its horizontal motion, the agent returns to a policy with
                        higher entropy. It is paying attention to the enemy moving right (<span
                            style="color: rgb(0, 255, 78); font-weight: 900; --darkreader-inline-color: #1aff60;"
                            data-darkreader-inline-color="">•</span>), which it is on track to avoid, but it cannot see
                        the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) obscured from view behind it. With some bad luck,
                        the agent happens to move right at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-obscured-10"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: Having adjusted its horizontal motion, the agent returns to a policy with
                        higher entropy. It is paying attention to the enemy moving right (<span
                            style="color: rgb(0, 255, 78); font-weight: 900; --darkreader-inline-color: #1aff60;"
                            data-darkreader-inline-color="">•</span>), which it is on track to avoid, but it cannot see
                        the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) obscured from view behind it. With some bad luck,
                        the agent happens to move right at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-obscured-11"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: Having adjusted its horizontal motion, the agent returns to a policy with
                        higher entropy. It is paying attention to the enemy moving right (<span
                            style="color: rgb(0, 255, 78); font-weight: 900; --darkreader-inline-color: #1aff60;"
                            data-darkreader-inline-color="">•</span>), which it is on track to avoid, but it cannot see
                        the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) obscured from view behind it. With some bad luck,
                        the agent happens to move right at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-obscured-12"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: Having adjusted its horizontal motion, the agent returns to a policy with
                        higher entropy. It is paying attention to the enemy moving right (<span
                            style="color: rgb(0, 255, 78); font-weight: 900; --darkreader-inline-color: #1aff60;"
                            data-darkreader-inline-color="">•</span>), which it is on track to avoid, but it cannot see
                        the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) obscured from view behind it. With some bad luck,
                        the agent happens to move right at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-obscured-13"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 14</b>: Finally the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) comes into view, and the agent tries to move left
                        to avoid it.
                    </div>
                    <div id="interface-failure-description-obscured-14"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 15</b>: For some reason the agent no longer seems to realize that it is on track to
                        collide with the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>), and returns to a policy with higher entropy. With
                        further bad luck, the agent again happens to move right.
                    </div>
                    <div id="interface-failure-description-obscured-15"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 16–17</b>: The danger of the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) becomes clear to the agent again. The agent tries
                        to move left to avoid it, and also prepares to immediately jump upon landing. Pulling off the
                        jump actually matters more to its chances of survival, since it is already moving right.
                    </div>
                    <div id="interface-failure-description-obscured-16"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 16–17</b>: The danger of the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) becomes clear to the agent again. The agent tries
                        to move left to avoid it, and also prepares to immediately jump upon landing. Pulling off the
                        jump actually matters more to its chances of survival, since it is already moving right.
                    </div>
                    <div id="interface-failure-description-obscured-17"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 18</b>: The agent makes a futile attempt to avoid the buzzsaw obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span>) by releasing up to jump, but it is too late, and
                        the episode is terminated.
                    </div>
                    <div id="interface-failure-description-down-0"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 1</b>: The agent prepares to jump, seeing the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) immediately in front of it. The agent cannot jump
                        when it is in mid-air, but jumping is only triggered when up is released, and it is allowed to
                        start pressing up before landing.
                    </div>
                    <div id="interface-failure-description-down-1"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 2–3</b>: The agent's policy is dominated by the 3 upward directions (which delay
                        the jump) and down (which cancels it). Any other action would trigger the jump. So the agent is
                        trying to delay the jump, partly because of the enemy moving left (<span
                            style="color: rgb(161, 255, 0); font-weight: 900; --darkreader-inline-color: #aaff1a;"
                            data-darkreader-inline-color="">•</span>), which both positively influences these actions
                        and negatively influences others.
                    </div>
                    <div id="interface-failure-description-down-2"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 2–3</b>: The agent's policy is dominated by the 3 upward directions (which delay
                        the jump) and down (which cancels it). Any other action would trigger the jump. So the agent is
                        trying to delay the jump, partly because of the enemy moving left (<span
                            style="color: rgb(161, 255, 0); font-weight: 900; --darkreader-inline-color: #aaff1a;"
                            data-darkreader-inline-color="">•</span>), which both positively influences these actions
                        and negatively influences others.
                    </div>
                    <div id="interface-failure-description-down-3"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 4</b>: The agent's policy is still dominated by the 3 updward directions and down,
                        and at this point the agent happens to move down. Unfortunately, the agent does not seem to have
                        taken into account that this will cause it to step down from the box it is standing on and onto
                        an enemy.
                    </div>
                    <div id="interface-failure-description-down-4"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 5</b>: The agent is now happier to jump by releasing up, based on the position of
                        the enemy moving left (<span
                            style="color: rgb(161, 255, 0); font-weight: 900; --darkreader-inline-color: #aaff1a;"
                            data-darkreader-inline-color="">•</span>), seeming not to realize that the jump has already
                        been cancelled.
                    </div>
                    <div id="interface-failure-description-down-5"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 6–7</b>: The agent returns to a policy dominated by the 3 upward directions and
                        down, seemingly influenced by the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) in front of it and, for some reason, the buzzsaw
                        obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span><span
                            style="color: rgb(0, 255, 255); font-weight: 900; --darkreader-inline-color: #1affff;"
                            data-darkreader-inline-color="">•</span>) behind it. The agent's apparent confusion may be
                        because it is already doomed, no matter which actions it takes.
                    </div>
                    <div id="interface-failure-description-down-6"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 6–7</b>: The agent returns to a policy dominated by the 3 upward directions and
                        down, seemingly influenced by the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) in front of it and, for some reason, the buzzsaw
                        obstacle (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span><span
                            style="color: rgb(0, 255, 255); font-weight: 900; --darkreader-inline-color: #1affff;"
                            data-darkreader-inline-color="">•</span>) behind it. The agent's apparent confusion may be
                        because it is already doomed, no matter which actions it takes.
                    </div>
                    <div id="interface-failure-description-offscreen-0"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 1</b>: The agent moves right across the platform (<span
                            style="color: rgb(0, 255, 255); font-weight: 900; --darkreader-inline-color: #1affff;"
                            data-darkreader-inline-color="">•</span> <span
                            style="color: rgb(0, 78, 255); font-weight: 900; --darkreader-inline-color: #3395ff;"
                            data-darkreader-inline-color="">•</span>) it is on.
                    </div>
                    <div id="interface-failure-description-offscreen-1"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 2</b>: The agent prepares to jump, seeing the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) across the other side of the chasm ahead of it.
                        Even though it is not yet at the edge of the platform it is currently on, it is timing its jump
                        so as to land on the nearest platform up ahead, perhaps because it can see that there are no
                        obstacles or enemies there.
                    </div>
                    <div id="interface-failure-description-offscreen-2"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timestep 3</b>: The agent jumps by releasing up.
                    </div>
                    <div id="interface-failure-description-offscreen-3"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 4–6</b>: The agent is in mid-air, trying to control its horizontal motion. Its
                        policy has higher entropy as its actions matter less at the start of a jump (due to the entropy
                        bonus used in PPO). Unfortunately, it happens to move left at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-offscreen-4"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 4–6</b>: The agent is in mid-air, trying to control its horizontal motion. Its
                        policy has higher entropy as its actions matter less at the start of a jump (due to the entropy
                        bonus used in PPO). Unfortunately, it happens to move left at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-offscreen-5"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 4–6</b>: The agent is in mid-air, trying to control its horizontal motion. Its
                        policy has higher entropy as its actions matter less at the start of a jump (due to the entropy
                        bonus used in PPO). Unfortunately, it happens to move left at every timestep during this period.
                    </div>
                    <div id="interface-failure-description-offscreen-6"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 7–8</b>: The agent notices that its horizontal velocity (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span> <span
                            style="color: rgb(255, 228, 0); font-weight: 900; --darkreader-inline-color: #ffe71a;"
                            data-darkreader-inline-color="">•</span> <span
                            style="color: rgb(255, 0, 228); font-weight: 900; --darkreader-inline-color: #ff1ae7;"
                            data-darkreader-inline-color="">•</span>) has been reduced, and tries to move right to
                        compensate. (Several features read from the velocity info as a secondary purpose.) With some bad
                        luck, it moves up but not right on its first move.
                    </div>
                    <div id="interface-failure-description-offscreen-7"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 7–8</b>: The agent notices that its horizontal velocity (<span
                            style="color: rgb(255, 0, 0); font-weight: 900; --darkreader-inline-color: #ff1a1a;"
                            data-darkreader-inline-color="">•</span> <span
                            style="color: rgb(255, 228, 0); font-weight: 900; --darkreader-inline-color: #ffe71a;"
                            data-darkreader-inline-color="">•</span> <span
                            style="color: rgb(255, 0, 228); font-weight: 900; --darkreader-inline-color: #ff1ae7;"
                            data-darkreader-inline-color="">•</span>) has been reduced, and tries to move right to
                        compensate. (Several features read from the velocity info as a secondary purpose.) With some bad
                        luck, it moves up but not right on its first move.
                    </div>
                    <div id="interface-failure-description-offscreen-8"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: The platforms have now moved below the agent's field of view. With little
                        to go by, its policy has high entropy, with some bias towards moving right rather than left.
                        With further bad luck, this rightward bias is not reflected in the actions sampled.
                    </div>
                    <div id="interface-failure-description-offscreen-9"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: The platforms have now moved below the agent's field of view. With little
                        to go by, its policy has high entropy, with some bias towards moving right rather than left.
                        With further bad luck, this rightward bias is not reflected in the actions sampled.
                    </div>
                    <div id="interface-failure-description-offscreen-10"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: The platforms have now moved below the agent's field of view. With little
                        to go by, its policy has high entropy, with some bias towards moving right rather than left.
                        With further bad luck, this rightward bias is not reflected in the actions sampled.
                    </div>
                    <div id="interface-failure-description-offscreen-11"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: The platforms have now moved below the agent's field of view. With little
                        to go by, its policy has high entropy, with some bias towards moving right rather than left.
                        With further bad luck, this rightward bias is not reflected in the actions sampled.
                    </div>
                    <div id="interface-failure-description-offscreen-12"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 9–13</b>: The platforms have now moved below the agent's field of view. With little
                        to go by, its policy has high entropy, with some bias towards moving right rather than left.
                        With further bad luck, this rightward bias is not reflected in the actions sampled.
                    </div>
                    <div id="interface-failure-description-offscreen-13"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 14–18</b>: As the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) across the other side of the chasm comes back into
                        view, the agent can see that its horizontal velocity (<span
                            style="color: rgb(255, 0, 228); font-weight: 900; --darkreader-inline-color: #ff1ae7;"
                            data-darkreader-inline-color="">•</span>) is not high enough, and so it tries to move right.
                    </div>
                    <div id="interface-failure-description-offscreen-14"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 14–18</b>: As the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) across the other side of the chasm comes back into
                        view, the agent can see that its horizontal velocity (<span
                            style="color: rgb(255, 0, 228); font-weight: 900; --darkreader-inline-color: #ff1ae7;"
                            data-darkreader-inline-color="">•</span>) is not high enough, and so it tries to move right.
                    </div>
                    <div id="interface-failure-description-offscreen-15"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 14–18</b>: As the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) across the other side of the chasm comes back into
                        view, the agent can see that its horizontal velocity (<span
                            style="color: rgb(255, 0, 228); font-weight: 900; --darkreader-inline-color: #ff1ae7;"
                            data-darkreader-inline-color="">•</span>) is not high enough, and so it tries to move right.
                    </div>
                    <div id="interface-failure-description-offscreen-16"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 14–18</b>: As the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) across the other side of the chasm comes back into
                        view, the agent can see that its horizontal velocity (<span
                            style="color: rgb(255, 0, 228); font-weight: 900; --darkreader-inline-color: #ff1ae7;"
                            data-darkreader-inline-color="">•</span>) is not high enough, and so it tries to move right.
                    </div>
                    <div id="interface-failure-description-offscreen-17"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 14–18</b>: As the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) across the other side of the chasm comes back into
                        view, the agent can see that its horizontal velocity (<span
                            style="color: rgb(255, 0, 228); font-weight: 900; --darkreader-inline-color: #ff1ae7;"
                            data-darkreader-inline-color="">•</span>) is not high enough, and so it tries to move right.
                    </div>
                    <div id="interface-failure-description-offscreen-18"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-19"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-20"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-21"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-22"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-23"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-24"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-25"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                    <div id="interface-failure-description-offscreen-26"
                        style="visibility: hidden; position: absolute; left: 20px; width: 560px; height: 115px;">
                        <b>Timesteps 19–27</b>: The agent realizes from the wall (<span
                            style="color: rgb(161, 0, 255); font-weight: 900; --darkreader-inline-color: #aa1aff;"
                            data-darkreader-inline-color="">•</span>) of the chasm that it has failed to complete the
                        jump. The value function plummets to below 5%, and the policy degenerates.
                    </div>
                </div>
            </div>
            <h3 id="hallucinations">Hallucinations</h3>
            <p>
                We searched for errors in the model using generalized advantage estimation (GAE) <d-cite key="gae">
                </d-cite>,<d-footnote id="d-footnote-6">We use the same GAE hyperparameters as in training, namely
                    <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>γ</mi>
                                            <mo>=</mo>
                                            <mn>0</mn>
                                            <mi mathvariant="normal">.</mi>
                                            <mn>9</mn>
                                            <mn>9</mn>
                                            <mn>9</mn>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\gamma=0.999</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.64444em;"></span><span class="strut bottom"
                                    style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span
                                    class="base"><span class="mord mathit" style="margin-right:0.05556em;">γ</span><span
                                        class="mrel">=</span><span class="mord mathrm">0</span><span
                                        class="mord mathrm">.</span><span class="mord mathrm">9</span><span
                                        class="mord mathrm">9</span><span
                                        class="mord mathrm">9</span></span></span></span></span> and <span><span
                            class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>λ</mi>
                                            <mo>=</mo>
                                            <mn>0</mn>
                                            <mi mathvariant="normal">.</mi>
                                            <mn>9</mn>
                                            <mn>5</mn>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\lambda=0.95</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.69444em;"></span><span class="strut bottom"
                                    style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathit">λ</span><span class="mrel">=</span><span
                                        class="mord mathrm">0</span><span class="mord mathrm">.</span><span
                                        class="mord mathrm">9</span><span
                                        class="mord mathrm">5</span></span></span></span></span>.
                </d-footnote> which
                measures how successful each action turned out relative to the agent’s expectations. An unusually high
                or low GAE indicates that either something unexpected occurred, or the agent’s expectations were
                miscalibrated. Filtering for such timesteps can therefore find problems with the value function or
                policy.
            </p>
            <p>
                Using our interface, we found a couple of cases in which the model “hallucinated” a feature not present
                in the observation, causing the value function to spike.
            </p>
            <table style="margin-top: 1em; margin-bottom: 0em;">
                <tbody>
                    <tr>
                        <td style="width: 30%; vertical-align: top;">
                            <label id="interface-bug-coin-label"
                                style="color: black; --darkreader-inline-color: #e8e6e3;"
                                data-darkreader-inline-color="">
                                <b><input type="radio" name="interface-bug-options" id="interface-bug-coin-option"
                                        checked=""> Coin hallucination</b>
                            </label><br>
                            <label id="interface-bug-saw-label"
                                style="color: lightgray; --darkreader-inline-color: #ccc8c1;"
                                data-darkreader-inline-color="">
                                <b><input type="radio" name="interface-bug-options" id="interface-bug-saw-option">
                                    Buzzsaw hallucination</b>
                            </label>
                        </td>
                        <td style="vertical-align: top;">
                            <div>
                                <div style="display: block;" id="interface-bug-coin-text">
                                    At one point the value function spiked upwards from 95% to 98% for a single
                                    timestep. This was due to a curved yellow-brown shape in the background, which
                                    happened to appear next to a wall, being mistaken for a coin.
                                </div>
                                <div style="display: none;" id="interface-bug-saw-text">
                                    At another point the value function spiked downwards from 94% to 85% for a single
                                    timestep. This was due to the agent, colored in gray-blue and crouching against a
                                    mottled background, being mistaken for a buzzsaw obstacle. An actual buzzsaw was
                                    also present in the observation, but the main effect was from the misjudged agent,
                                    as shown by the larger red circle around the agent (hover over the first legend item
                                    to isolate).
                                </div>
                            </div>
                        </td>
                    </tr>
                </tbody>
            </table>
            <h3 id="model-editing">Model editing</h3>
            <p>
                Our analysis so far has been mostly qualitative. To quantitatively validate our analysis, we hand-edited
                the model to make the agent blind to certain features identified by our interface: buzzsaw obstacles in
                one case, and left-moving enemies in another. Our method for this can be thought of as a primitive form
                of <a href="https://distill.pub/2020/circuits/">circuit</a>-editing <d-cite key="circuits"></d-cite>,
                and we explain it in detail in <a href="#model-editing-method">Appendix A</a>.
            </p>
            <p>
                We evaluated each edit by measuring the percentage of levels that the new agent failed to complete,
                broken down by the object that the agent collided with to cause the failure. Our results show that our
                edits were successful and targeted, with no statistically measurable effects on the agent’s other
                abilities.<d-footnote id="d-footnote-7">The data for this plot are as follows.<br>Percentage of levels
                    failed due to: buzzsaw obstacle / enemy moving left / enemy moving right / multiple or other:<br>-
                    Original model: 0.37% / 0.16% / 0.12% / 0.08%<br>- Buzzsaw obstacle blindness: 12.76% / 0.16% /
                    0.08% / 0.05%<br>- Enemy moving left blindness: 0.36% / 4.69% / 0.97% / 0.07%<br>Each model was
                    tested on 10,000 levels.</d-footnote>
            </p>
            <p>
                We did not manage to achieve complete blindness, however: the buzzsaw-edited model still performed
                significantly better than the original model did when we made the buzzsaws completely invisible.
                <d-footnote id="d-footnote-8">Our results on the version of the game with invisible buzzsaws are as
                    follows.<br>Percentage of levels failed due to: buzzsaw obstacle / enemy moving left / enemy moving
                    right / multiple or other:<br>Original model, invisible buzzsaws: 32.20% / 0.05% / 0.05% /
                    0.05%<br>We tested the model on 10,000 levels.<br>We experimented briefly with iterating the editing
                    procedure, but were not able to achieve more than around 50% buzzsaw blindness by this metric
                    without affecting the model’s other abilities.</d-footnote> This implies that the model has other
                ways of detecting buzzsaws than the feature identified by our interface.
            </p>
            <p>
                Here are the original and edited models playing some cherry-picked levels.
            </p>
            <h2 id="diversity-hypothesis">The diversity hypothesis</h2>
            <p>
                All of the above analysis uses the same hidden layer of our network, the third of five convolutional
                layers, since it was much harder to find interpretable features at other layers. Interestingly, the
                level of abstraction at which this layer operates – finding the locations of various in-game objects –
                is exactly the level at which CoinRun levels are randomized using procedural generation. Furthermore, we
                found that training on many randomized levels was essential for us to be able to find any interpretable
                features at all.
            </p>
            <p>
                This led us to suspect that the diversity introduced by CoinRun’s randomization is linked to the
                formation of interpretable features. We call this the <span style="font-style: italic;">diversity
                    hypothesis</span>:
            </p>
            <blockquote>
                Interpretable features tend to arise (at a given level of abstraction) if and only if the training
                distribution is diverse enough (at that level of abstraction).
            </blockquote>
            <p>
                Our explanation for this hypothesis is as follows. For the forward implication (“only if”), we only
                expect features to be interpretable if they are general enough, and when the training distribution is
                not diverse enough, models have no incentive to develop features that generalize instead of overfitting.
                For the reverse implication (“if”), we do not expect it to hold in a strict sense: diversity on its own
                is not enough to guarantee the development of interpretable features, since they must also be relevant
                to the task. Rather, our intention with the reverse implication is to hypothesize that it holds very
                often in practice, as a result of generalization being bottlenecked by diversity.
            </p>
            <p>
                In CoinRun, procedural generation is used to incentivize the model to learn skills that generalize to
                unseen levels <d-cite key="procgen,gvgai,obstacletower"></d-cite>. However, only the <span
                    style="font-style: italic;">layout</span> of each level is randomized, and correspondingly, we were
                only able to find interpretable features at the level of abstraction of objects. At a lower level, there
                are only a handful of visual patterns in the game, and the low-level features of our model seem to
                consist mostly of memorized color configurations used for picking these out. Similarly, the game’s
                high-level dynamics follow a few simple rules, and accordingly the high-level features of our model seem
                to involve mixtures of combinations of objects that are hard to decipher. To explore the other
                convolutional layers, see the interface <a
                    href="https://openaipublic.blob.core.windows.net/rl-clarity/attribution/demo/interface.html">here</a>.
            </p>
            <h3 id="interpretability-and-generalization">Interpretability and generalization</h3>
            <p>
                To test our hypothesis, we made the training distribution less diverse, by training the agent on a fixed
                set of 100 levels. This dramatically reduced our ability to interpret the model’s features. Here we
                display an interface for the new model, generated in the same way as the one <a
                    href="#interface">above</a>. The smoothly increasing value function suggests that the model has
                memorized the number of timesteps until the end of the level, and the features it uses for this focus on
                irrelevant background objects. Similar overfitting occurs for other video games with a limited number of
                levels <d-cite key="sonicsaliency"></d-cite>.
            </p>
            <p>
                We attempted to quantify this effect by varying the number of levels used to train the agent, and
                evaluating the 8 features identified by our interface on how interpretable they were.<d-footnote
                    id="d-footnote-9">The interfaces used for this evaluation can be found <a
                        href="https://openaipublic.blob.core.windows.net/rl-clarity/attribution/finite_levels/index.html">here</a>.
                </d-footnote> Features were scored based on how consistently they focused on the same objects, and
                whether the value function attribution made sense – for example, background objects should not be
                relevant. This process was subjective and noisy, but that may be unavoidable. We also measured the
                generalization ability of each model, by testing the agent on unseen levels <d-cite key="coinrunpaper">
                </d-cite>.<d-footnote id="d-footnote-10">The data for this plot are as follows.<br>- Number of training
                    levels: 100 / 300 / 1000 / 3,000 / 10,000 / 30,000 / 100,000<br>- Percentage of levels completed
                    (train, run 1): 99.96% / 99.82% / 99.67% / 99.65% / 99.47% / 99.55% / 99.57%<br>- Percentage of
                    levels completed (train, run 2): 99.97% / 99.86% / 99.70% / 99.46% / 99.39% / 99.50% / 99.37%<br>-
                    Percentage of levels completed (test, run 1): 61.81% / 66.95% / 74.93% / 89.87% / 97.53% / 98.66% /
                    99.25%<br>- Percentage of levels completed (test, run 2): 64.13% / 67.64% / 73.46% / 90.36% / 97.44%
                    / 98.89% / 99.35%<br>- Percentage of features interpretable (researcher 1, run 1): 52.5% / 22.5% /
                    11.25% / 45% / 90% / 75% / 91.25%<br>- Percentage of features interpretable (researcher 2, run 1):
                    8.75% / 8.75% / 10% / 26.25% / 56.25% / 90% / 70%<br>- Percentage of features interpretable
                    (researcher 1, run 2): 15% / 13.75% / 15% / 23.75% / 53.75% / 90% / 96.25%<br>- Percentage of
                    features interpretable (researcher 2, run 2): 3.75% / 6.25% / 21.25% / 45% / 72.5% / 83.75% /
                    77.5%<br>Percentages of levels completed are estimated by sampling 10,000 levels with replacement.
                </d-footnote>
            </p>
            <p>
                Our results illustrate how diversity may lead to interpretable features via generalization, lending
                support to the diversity hypothesis. Nevertheless, we still consider the hypothesis to be highly
                unproven.
            </p>
            <h2 id="feature-visualization">Feature visualization</h2>
            <p>
                <a href="https://distill.pub/2017/feature-visualization/">Feature visualization</a>
                <d-cite key="attribution1,featurevis,featurevis1,featurevis2,featurevis3,featurevis4"></d-cite> answers
                questions about what certain parts of a network are looking for by generating examples. This can be done
                by applying gradient descent to the input image, starting from random noise, with the objective of
                activating a particular neuron or group of neurons. While this method works well for an image classifier
                trained on ImageNet <d-cite key="imagenet"></d-cite>, for our CoinRun model it yields only featureless
                clouds of color. Only for the first layer, which computes simple convolutions of the input, does the
                method produce comparable visualizations for the two models.
            </p>
            <p>
                Gradient-based feature visualization has previously been shown to struggle with RL models trained on
                Atari games <d-cite key="atarimodelzoo,atarifeaturevis"></d-cite>. To try to get it to work for CoinRun,
                we varied the method in a number of ways. Nothing we tried had any noticeable effect on the quality of
                the visualizations.
            </p>
            <ul>
                <li><b>Transformation robustness.</b> This is the method of stochastically jittering, rotating and
                    scaling the image between optimization steps, to search for examples that are robust to these
                    transformations <d-cite key="featurevis"></d-cite>. We tried both increasing and decreasing the size
                    of the jittering. Rotating and scaling are less appropriate for CoinRun, since the observations
                    themselves are not invariant to these transformations.</li>
                <li id="extremal-colors"><b>Penalizing extremal colors.</b>
                    <d-footnote id="d-footnote-12">By an “extremal” color we mean one of the 8 colors with maximal or
                        minimal RGB values (black, white, red, green, blue, yellow, cyan and magenta).</d-footnote>
                    Noticing that our visualizations tend to use extremal colors towards the middle, we tried including
                    in the visualization objective an L2 penalty of various strengths on the activations of the first
                    layer, which successfully reduced the size of the extremally-colored region but did not otherwise
                    help.
                </li>
                <li><b>Alternative objectives.</b> We tried using an alternative optimization objective <d-cite
                        key="featurevis"></d-cite>, such as the caricature objective.<d-footnote id="d-footnote-13">The
                        caricature objective is to maximize the dot product between the activations of the input image
                        and the activations of a reference image. Caricatures are often an especially easy type of
                        feature visualization to make work, and helpful for getting a first glance into what features a
                        model has. They are demonstrated in <a
                            href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/feature_inversion_caricatures.ipynb">this
                            notebook</a>. A more detailed manuscript by its authors <d-cite key="caricatures"></d-cite>
                        is forthcoming.</d-footnote> We also tried using dimensionality reduction, as described <a
                        href="#dataset-examples">below</a>, to choose non-axis-aligned directions in activation space to
                    maximize.
                </li>
                <li><b>Low-level visual diversity.</b> In an attempt to broaden the distribution of images seen by the
                    model, we retrained it on a version of the game with procedurally-generated sprites. We additionally
                    tried adding noise to the images, both independent per-pixel noise and spatially-correlated noise.
                    Finally, we experimented briefly with adversarial training <d-cite key="adversarialtraining">
                    </d-cite>, though we did not pursue this line of inquiry very far.</li>
            </ul>
            <p id="feature-visualization-discussion">
                As shown <a href="#dataset-examples">below</a>, we were able to use dataset examples to identify a
                number of channels that pick out human-interpretable features. It is therefore striking how resistant
                gradient-based methods were to our efforts. We believe that this is because solving CoinRun does not
                ultimately require much visual ability. Even with our modifications, it is possible to solve the game
                using simple visual shortcuts, such as picking out certain small configurations of pixels. These
                shortcuts work well on the narrow distribution of images on which the model is trained, but behave
                unpredictably in the full space of images in which gradient-based optimization takes place.
            </p>
            <p>
                Our analysis here provides further insight into the <a href="#diversity-hypothesis">diversity
                    hypothesis</a>. In support of the hypothesis, we have examples of features that are hard to
                interpret in the absence of diversity. But there is also evidence that the hypothesis may need to be
                refined. Firstly, it seems to be a lack of diversity at a low level of abstraction that harms our
                ability to interpret features at all levels of abstraction, which could be due to the fact that
                gradient-based feature visualization needs to back-propagate through earlier layers. Secondly, the
                failure of our efforts to increase low-level visual diversity suggests that diversity may need to be
                assessed in the context of the requirements of the task.
            </p>
            <h3 id="dataset-examples">Dataset example-based feature visualization</h3>
            <p>
                As an alternative to gradient-based feature visualization, we use dataset examples. This idea has a long
                history, and can be thought of as a heavily-regularized form of feature visualization <d-cite
                    key="featurevis,featurevisadversarial"></d-cite>. In more detail, we sample a few thousand
                observations infrequently from the agent playing the game, and pass them through the model. We then
                apply a dimensionality reduction method known as non-negative matrix factorization (NMF) to the
                activation channels <d-cite key="buildingblocks"></d-cite>.<d-footnote id="d-footnote-14">More
                    precisely, we find a non-negative approximate low-rank factorization of the matrix obtained by
                    flattening the spatial dimensions of the activations into the batch dimension. This matrix has one
                    row per observation <i>per spatial position</i> and one column per channel: thus the dimensionality
                    reduction does not use spatial information.</d-footnote> For each of the resulting channels (which
                correspond to weighted combinations of the original channels), we choose the observations and spatial
                positions with the strongest activation (with a limited number of examples per position, for diversity),
                and display a patch from the observation at that position.
            </p>
            <p>
                Unlike gradient-based feature visualization, this method finds some meaning to the different directions
                in activation space. However, it may still fail to provide a complete picture for each direction, since
                it only shows a limited number of dataset examples, and with limited context.
            </p>
            <h3 id="feature-visualization-spatial">Spatially-aware feature visualization</h3>
            <p>
                CoinRun observations differ from natural images in that they are much less spatially invariant. For
                example, the agent always appears in the center, and the agent’s velocity is always encoded in the top
                left. As a result, some features detect unrelated things at different spatial positions, such as reading
                the agent’s velocity in the top left while detecting an unrelated object elsewhere. To account for this,
                we developed a spatially-aware version of dataset example-based feature visualization, in which we fix
                each spatial position in turn, and choose the observation with the strongest activation at that position
                (with a limited number of reuses of the same observation, for diversity). This creates a spatial
                correspondence between visualizations and observations.
            </p>
            <p>
                Here is such a visualization for a feature that responds strongly to coins. The white squares in the top
                left show that the feature also responds strongly to the horizontal velocity info when it is white,
                corresponding to the agent moving right at full speed.
            </p>
            <h2 id="attribution">Attribution</h2>
            <p>
                Attribution <d-cite
                    key="attribution1,attribution2,attribution3,gradcam,attribution4,attribution5,attribution6,integratedgradients">
                </d-cite> answers questions about the relationships between neurons. It is most commonly used to see how
                the input to a network affects a particular output – for example, in RL <d-cite
                    key="perturbationsaliency,sarfa"></d-cite> – but it can also be applied to the activations of hidden
                layers <d-cite key="buildingblocks"></d-cite>. Although there are many approaches to attribution we
                could have used, we chose the method of integrated gradients <d-cite key="integratedgradients"></d-cite>
                . We explain in <a href="#integrated-gradients">Appendix B</a> how we applied this method a hidden
                layer, and how positive value function attribution can be thought of as “good news” and negative value
                function attribution can as “bad news”.
            </p>
            <h3 id="dimensionality-reduction">Dimensionality reduction for attribution</h3>
            <p>
                We showed <a href="#dataset-examples">above</a> that a dimensionality reduction method known as
                non-negative matrix factorization (NMF) could be applied to the channels of activations to produce
                meaningful directions in activation space <d-cite key="buildingblocks"></d-cite>. We found that it is
                even more effective to apply NMF not to activations, but to <span style="font-style: italic;">value
                    function attributions</span>
                <d-footnote id="d-footnote-15">As before, we obtain the NMF directions by sampling a few thousand
                    observations infrequently from the agent playing the game, computing the attributions, flattening
                    the spatial dimensions into the batch dimension, and applying NMF.</d-footnote> (working around the
                fact that NMF can only be applied to non-negative matrices<d-footnote id="d-footnote-16">Our workaround
                    is to separate out the positive and negative parts of the attributions and concatenate them along
                    the batch dimension. We could also have concatenated them along the channel dimension.</d-footnote>
                ). Both methods tend to produce NMF directions that are close to one-hot, and so can be thought of as
                picking out the most relevant channels. However, when reducing to a small number of dimensions, using
                attributions usually picks out more salient features, because attribution takes into account not just
                <span style="font-style: italic;">what neurons respond to</span> but also <span
                    style="font-style: italic;">whether their response matters</span>.
            </p>
            <p>
                Following <d-cite key="buildingblocks"></d-cite>, after applying NMF to attributions, we visualize them
                by assigning a different color to each of the resulting channels. We overlay these visualizations over
                the observation <d-cite key="gradcam"></d-cite> and contextualize each channel using feature
                visualization <d-cite key="buildingblocks"></d-cite>, making use of <a href="#dataset-examples">dataset
                    example-based feature visualization</a>. This gives a basic version of our interface, which allows
                us to see the effect of the main features at different spatial positions.
            </p>
            <p>
                For the <a href="#interface">full version</a> of our interface, we simply repeat this for an entire
                trajectory of the agent playing the game. We also incorporate video controls, a timeline view of
                compressed observations <d-cite key="rmo"></d-cite>, and additional information, such as model outputs
                and sampled actions. Together these allow the trajectory to be easily explored and understood.
            </p>
            <h3 id="attribution-discussion">Attribution discussion</h3>
            <p>
                Attributions for our CoinRun model have some interesting properties that would be unusual for an
                ImageNet model.
            </p>
            <ul>
                <li><b>Sparsity.</b> Attribution tends to be concentrated in a very small number of spatial positions
                    and (post-NMF) channels. For example, in the figure above, the top 10 position–channel pairs account
                    for more than 80% of the total absolute attribution. This might be explained by our <a
                        href="#feature-visualization-discussion">earlier</a> hypothesis that the model identifies
                    objects by picking out certain small configurations of pixels. Because of this sparsity, we smooth
                    out attribution over nearby spatial positions for the full version of our interface, so that the
                    amount of visual space taken up can be used to judge attribution strength. This trades off some
                    spatial precision for more precision with magnitudes.</li>
                <li><b>Unexpected sign.</b> Value function attribution usually has the sign one would expect: positive
                    for coins, negative for enemies, and so on. However, this is sometimes not the case. For example, in
                    the figure above, the red channel that detects buzzsaw obstacles has both positive and negative
                    attribution in two neighboring spatial positions towards the left. Our best guess is that this
                    phenomenon is a result of statistical <a
                        href="https://en.wikipedia.org/wiki/Multicollinearity">collinearity</a>, caused by certain
                    correlations in the procedural level generation together with the agent’s behavior. These could be
                    visual, such as correlations between nearby pixels, or more abstract, such as both coins and long
                    walls appearing at the end of every level. As a toy example, supposing the value function ought to
                    increase by 2% when the end of the level becomes visible, the model could either increase the value
                    function by 1% for coins and 1% for long walls, or by 3% for coins and −1% for long walls, and the
                    effect would be similar.</li>
                <li><b>Outlier frames.</b> When an unusual event causes the network to output extreme values,
                    attribution can behave especially strangely. For example, in the <a id="bug-saw-link"
                        href="#hallucinations">buzzsaw hallucination</a> frame, most features have a significant amount
                    of both positive and negative attribution. We do not have a good explanation for this, but perhaps
                    features are interacting in more complicated ways than usual. Moreover, in these cases there is
                    often a significant component of the attribution lying outside the space spanned by the NMF
                    directions, which we display as an additional “residual” feature. This could be because each frame
                    is weighted equally when computing NMF, so outlier frames have little influence over the NMF
                    directions.</li>
            </ul>
            <p>
                These considerations suggest that some care may be required when interpreting attributions.
            </p>
            <h2 id="questions">Questions for further research</h2>
            <h3>The <a href="#diversity-hypothesis">diversity hypothesis</a></h3>
            <ol>
                <li><b>Validity.</b> Does the diversity hypothesis hold in other contexts, both within and outside of
                    reinforcement learning?</li>
                <li><b>Relationship to generalization.</b> What is the three-way relationship between diversity,
                    interpretable features and generalization? Do non-interpretable features indicate that a model will
                    fail to generalize in certain ways? Generalization refers implicitly to an underlying distribution –
                    how should this distribution be chosen?<d-footnote id="d-footnote-17">For example, to measure
                        generalization for CoinRun models trained on a limited number of levels, we used the
                        distribution over all possible procedurally-generated levels. However, to formalize the sense in
                        which CoinRun is not diverse in its visual patterns or dynamics rules, one would need a
                        distribution over levels from a wider class of games.</d-footnote>
                </li>
                <li><b>Caveats.</b> How are interpretable features affected by other factors, such as the choice of task
                    or algorithm, and how do these interact with diversity? Speculatively, do big enough models obtain
                    interpretable features via the double descent phenomenon <d-cite key="doubledescent"></d-cite>, even
                    in the absence of diversity?</li>
                <li><b>Quantification.</b> Can we quantitatively predict how much diversity is needed for interpretable
                    features, perhaps using generalization metrics? Can we be precise about what is meant by an
                    “interpretable feature” and a “level of abstraction”?</li>
            </ol>
            <h3>Interpretability in the absence of diversity</h3>
            <ol>
                <li><b>Pervasiveness of non-diverse features.</b> Do “non-diverse features”, by which we mean the
                    hard-to-interpret features that tend to arise in the absence of diversity, remain when diversity is
                    present? Is there a connection between these non-diverse features and the “non-robust features” that
                    have been posited to explain adversarial examples <d-cite
                        key="advexfeatures,advexfeaturesdiscussion"></d-cite>?</li>
                <li><b>Coping with non-diverse levels of abstraction.</b> Are there levels of abstraction at which even
                    broad distributions like ImageNet remain non-diverse, and how can we best interpret models at these
                    levels of abstraction?</li>
                <li><b>Gradient-based feature visualization.</b> Why does gradient-based feature visualization <a
                        href="#feature-visualization">break down</a> in the absence of diversity, and can it be made to
                    work using transformation robustness, regularization, data augmentation, adversarial training, or
                    other techniques? What property of the optimization leads to the clouds of <a
                        href="#extremal-colors">extremal colors</a>?</li>
                <li><b>Trustworthiness of dataset examples and attribution.</b> How reliable and trustworthy can we make
                    very heavily-regularized versions of feature visualization, such as those based on <a
                        href="#dataset-examples">dataset examples</a>?<d-footnote id="d-footnote-18">Heavily-regularized
                        feature visualization may be untrustworthy by failing to separate the things causing certain
                        behavior from the things that merely correlate with those causes <d-cite key="featurevis">
                        </d-cite>.</d-footnote> What explains the <a href="#attribution-discussion">strange behavior</a>
                    of attribution, and how trustworthy is it?</li>
            </ol>
            <h3>Interpretability in the RL framework</h3>
            <ol>
                <li><b>Non-visual and abstract features.</b> What are the best methods for interpreting models with
                    non-visual inputs? Even vision models may also have interpretable abstract features, such as
                    relationships between objects or anticipated events: will any method of generating examples be
                    enough to understand these, or do we need an entirely new approach? For models with memory, how can
                    we interpret their hidden states <d-cite key="capturetheflag,rubik,dota"></d-cite>?</li>
                <li><b>Improving reliability.</b> How can we best identify, understand and correct rare <a
                        href="#dissecting-failure">failures</a> and <a href="#hallucinations">other errors</a> in RL
                    models? Can we actually improve models by <a href="#model-editing">model editing</a>, rather than
                    merely degrading them?</li>
                <li><b>Modifying training.</b> In what ways can we train RL models to make them more interpretable
                    without a significant performance cost, such as by altering architectures or adding auxiliary
                    predictive losses?</li>
                <li><b>Leveraging the environment.</b> How can we enrich interfaces using RL-specific data, such as
                    trajectories of agent–environment interaction, state distributions, and advantage estimates? What
                    are the benefits of incorporating user–environment interaction, such as for exploring
                    counterfactuals?</li>
            </ol>
            <h3 id="questions-discussion">What we would like to see from further research and why</h3>
            <p>
                We are motivated to study interpretability for RL for two reasons.
            </p>
            <ul>
                <li><b>To be able to interpret RL models.</b> RL can be applied to an enormous variety of tasks, and
                    seems likely to be a part of increasingly influential AI systems. It is therefore important to be
                    able to scrutinize RL models and to understand how they might fail. This may also benefit RL
                    research through an improved understanding of the pitfalls of different algorithms and environments.
                </li>
                <li><b>As a testbed for interpretability techniques.</b> RL models pose a number of distinctive
                    challenges for interpretability techniques. In particular, environments like CoinRun straddle the
                    boundary between memorization and generalization, making them useful for studying the <a
                        href="#diversity-hypothesis">diversity hypothesis</a> and related ideas.</li>
            </ul>
            <p>
                We think that large neural networks are currently the most likely type of model to be used in highly
                capable and influential AI systems in the future. Contrary to the traditional perception of neural
                networks as black boxes, we think that there is a fighting chance that we will be able to clearly and
                thoroughly understand the behavior even of very large networks. We are therefore most excited by neural
                network interpretability research that scores highly according to the following criteria.
            </p>
            <ul>
                <li><b>Scalability.</b> The takeaways of the research should have some chance of scaling to harder
                    problems and larger networks. If the techniques themselves do not scale, they should at least reveal
                    some relevant insight that might.</li>
                <li><b>Trustworthiness.</b> Explanations should be faithful to the model. Even if they do not tell the
                    full story, they should at least not be biased in some fatal way (such as by using an approval-based
                    objective that leads to bad explanations that sound good, or by depending on another model that
                    badly distorts information).</li>
                <li><b>Exhaustiveness.</b> This may turn out to be impossible at scale, but we should strive for
                    techniques that explain every essential feature of our models. If there are theoretical limits to
                    exhaustiveness, we should try to understand these.</li>
                <li><b>Low cost.</b> Our techniques should not be significantly more computationally expensive than
                    training the model. We hope that we will not need to train models differently for them to be
                    interpretable, but if we do, we should try to minimize both the computational expense and any
                    performance cost, so that interpretable models are not disincentivized from being used in practice.
                </li>
            </ul>
            <p>
                Our proposed questions reflect this perspective. One of the reasons we emphasize diversity relates to
                exhaustiveness. If “non-diverse features” remain when diversity is present, then our current techniques
                are not exhaustive and could end up missing important features of more capable models. Developing tools
                to understand non-diverse features may shed light on whether this is likely to be a problem.
            </p>
            <p>
                We think there may be significant mileage in simply applying existing interpretability techniques, with
                attention to detail, to more models. Indeed, this was the mindset with which we initially approached
                this project. If the diversity hypothesis is correct, then this may become easier as we train our models
                to perform more complex tasks. Like early biologists encountering a new species, there may be a lot we
                can glean from taking a magnifying glass to the creatures in front of us.
            </p>
            <h2 id="supplementary-material">Supplementary material</h2>
            <ul>
                <li><b>Code.</b> Utilities for computing feature visualization, attribution and dimensionality reduction
                    for our models can be found in <code>lucid.scratch.rl_util</code>, a submodule of <a
                        href="https://github.com/tensorflow/lucid">Lucid</a>. We demonstrate these in a <a
                        href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/rl_util.ipynb"><img
                            src="images/colab.svg"> notebook</a>.</li>
                <li><b>Model weights.</b> The weights of our model are available for download, along with those of a
                    number of other models, including the models trained on different numbers of levels, the edited
                    models, and models trained on all 16 of the Procgen Benchmark <d-cite key="procgen"></d-cite> games.
                    These are indexed <a
                        href="https://openaipublic.blob.core.windows.net/rl-clarity/attribution/models/index.html">here</a>.
                </li>
                <li><b>More interfaces.</b> We generated an expanded version of our interface for every convolutional
                    layer in our model, which can be found <a
                        href="https://openaipublic.blob.core.windows.net/rl-clarity/attribution/demo/interface.html">here</a>.
                    We also generated similar interfaces for each of our other models, which are indexed <a
                        href="https://openaipublic.blob.core.windows.net/rl-clarity/attribution/index.html">here</a>.
                </li>
                <li><b>Interface code.</b> The code used to generate the expanded version of our interface can be found
                    <a href="https://github.com/openai/understanding-rl-vision">here</a>.
                </li>
            </ul>

        </d-article>
        <d-appendix id="appendix">

            <h3 id="model-editing-method">Appendix A: Model editing method</h3>
            <p>
                Here we explain our method for <a href="#model-editing">editing the model</a> to make the agent blind to
                certain features.
            </p>
            <p>
                The features in our interface correspond to directions in activation space obtained by applying <a
                    href="#dimensionality-reduction">attribution-based NMF</a> to layer <a href="#architecture">2b</a>
                of our model. To blind the agent to a feature, we edit the weights to make them project out the
                corresponding NMF direction.
            </p>
            <p>
                More precisely, let <span><span class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi mathvariant="bold">v</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">\mathbf v</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.44444em;"></span><span class="strut bottom"
                                style="height:0.44444em;vertical-align:0em;"></span><span class="base"><span
                                    class="mord mathbf"
                                    style="margin-right:0.01597em;">v</span></span></span></span></span> be the NMF
                direction corresponding to the feature we wish to blind the model to. This is a vector of length
                <span><span class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi>c</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">c</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.43056em;"></span><span class="strut bottom"
                                style="height:0.43056em;vertical-align:0em;"></span><span class="base"><span
                                    class="mord mathit">c</span></span></span></span></span>, the number of channels in
                activation space. Using this we construct the <a
                    href="https://en.wikipedia.org/wiki/Projection_(linear_algebra)">orthogonal projection</a> matrix
                <span><span class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi>P</mi>
                                        <mo>:</mo>
                                        <mo>=</mo>
                                        <mi>I</mi>
                                        <mo>−</mo>
                                        <mfrac>
                                            <mn>1</mn>
                                            <mrow>
                                                <mi mathvariant="normal">∥</mi>
                                                <mi mathvariant="bold">v</mi>
                                                <msup>
                                                    <mi mathvariant="normal">∥</mi>
                                                    <mn>2</mn>
                                                </msup>
                                            </mrow>
                                        </mfrac>
                                        <mi mathvariant="bold">v</mi>
                                        <msup>
                                            <mi mathvariant="bold">v</mi>
                                            <mi mathvariant="sans-serif">T</mi>
                                        </msup>
                                    </mrow>
                                    <annotation encoding="application/x-tex">P:=I-\frac 1{\|\mathbf v\|^2}\mathbf
                                        v\mathbf v^{\mathsf T}</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.849108em;"></span><span class="strut bottom"
                                style="height:1.369108em;vertical-align:-0.52em;"></span><span class="base"><span
                                    class="mord mathit" style="margin-right:0.13889em;">P</span><span
                                    class="mrel">:</span><span class="mrel">=</span><span class="mord mathit"
                                    style="margin-right:0.07847em;">I</span><span class="mbin">−</span><span
                                    class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span
                                            class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                    style="height:0.845108em;"><span style="top:-2.655em;"><span
                                                            class="pstrut" style="height:3em;"></span><span
                                                            class="sizing reset-size6 size3 mtight"><span
                                                                class="mord mtight"><span
                                                                    class="mord mathrm mtight">∥</span><span
                                                                    class="mord mathbf mtight"
                                                                    style="margin-right:0.01597em;">v</span><span
                                                                    class="mord mtight"><span
                                                                        class="mord mathrm mtight">∥</span><span
                                                                        class="msupsub"><span class="vlist-t"><span
                                                                                class="vlist-r"><span class="vlist"
                                                                                    style="height:0.7463142857142857em;"><span
                                                                                        style="top:-2.786em;margin-right:0.07142857142857144em;"><span
                                                                                            class="pstrut"
                                                                                            style="height:2.5em;"></span><span
                                                                                            class="sizing reset-size3 size1 mtight"><span
                                                                                                class="mord mathrm mtight">2</span></span></span></span></span></span></span></span></span></span></span><span
                                                        style="top:-3.23em;"><span class="pstrut"
                                                            style="height:3em;"></span><span class="frac-line"
                                                            style="border-bottom-width:0.04em;"></span></span><span
                                                        style="top:-3.394em;"><span class="pstrut"
                                                            style="height:3em;"></span><span
                                                            class="sizing reset-size6 size3 mtight"><span
                                                                class="mord mathrm mtight">1</span></span></span></span><span
                                                    class="vlist-s">​</span></span><span class="vlist-r"><span
                                                    class="vlist"
                                                    style="height:0.52em;"></span></span></span></span><span
                                        class="mclose nulldelimiter"></span></span><span class="mord mathbf"
                                    style="margin-right:0.01597em;">v</span><span class="mord"><span class="mord mathbf"
                                        style="margin-right:0.01597em;">v</span><span class="msupsub"><span
                                            class="vlist-t"><span class="vlist-r"><span class="vlist"
                                                    style="height:0.849108em;"><span
                                                        style="top:-3.063em;margin-right:0.05em;"><span class="pstrut"
                                                            style="height:2.7em;"></span><span
                                                            class="sizing reset-size6 size3 mtight"><span
                                                                class="mord mtight"><span
                                                                    class="mord mathsf mtight">T</span></span></span></span></span></span></span></span></span></span></span></span></span>,
                which projects out the direction of <span><span class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi mathvariant="bold">v</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">\mathbf v</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.44444em;"></span><span class="strut bottom"
                                style="height:0.44444em;vertical-align:0em;"></span><span class="base"><span
                                    class="mord mathbf"
                                    style="margin-right:0.01597em;">v</span></span></span></span></span> from activation
                vectors. We then take the convolutional kernel of the following layer, which has shape <span><span
                        class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mtext>height</mtext>
                                        <mo>×</mo>
                                        <mtext>width</mtext>
                                        <mo>×</mo>
                                        <mi>c</mi>
                                        <mo>×</mo>
                                        <mi>d</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">\text{height}\times\text{width}\times
                                        c\times d</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.69444em;"></span><span class="strut bottom"
                                style="height:0.8888799999999999em;vertical-align:-0.19444em;"></span><span
                                class="base"><span class="mord text"><span class="mord mathrm">height</span></span><span
                                    class="mbin">×</span><span class="mord text"><span
                                        class="mord mathrm">width</span></span><span class="mbin">×</span><span
                                    class="mord mathit">c</span><span class="mbin">×</span><span
                                    class="mord mathit">d</span></span></span></span></span>, where <span><span
                        class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi>d</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">d</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.69444em;"></span><span class="strut bottom"
                                style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span
                                    class="mord mathit">d</span></span></span></span></span> is the number of output
                channels. Broadcasting across the height and width dimensions, we left-multiply each <span><span
                        class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi>c</mi>
                                        <mo>×</mo>
                                        <mi>d</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">c\times d</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.69444em;"></span><span class="strut bottom"
                                style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="base"><span
                                    class="mord mathit">c</span><span class="mbin">×</span><span
                                    class="mord mathit">d</span></span></span></span></span> matrix in the kernel by
                <span><span class="katex"><span class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi>P</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">P</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.68333em;"></span><span class="strut bottom"
                                style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span
                                    class="mord mathit"
                                    style="margin-right:0.13889em;">P</span></span></span></span></span>. The effect of
                the new kernel is to project out the direction of <span><span class="katex"><span
                            class="katex-mathml"><math>
                                <semantics>
                                    <mrow>
                                        <mi mathvariant="bold">v</mi>
                                    </mrow>
                                    <annotation encoding="application/x-tex">\mathbf v</annotation>
                                </semantics>
                            </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                style="height:0.44444em;"></span><span class="strut bottom"
                                style="height:0.44444em;vertical-align:0em;"></span><span class="base"><span
                                    class="mord mathbf"
                                    style="margin-right:0.01597em;">v</span></span></span></span></span> from
                activations before applying the original kernel.
            </p>
            <p>
                As it turned out, the NMF directions were close to one-hot, so this procedure is approximately
                equivalent to zeroing out the slice of the kernel corresponding to a particular in-channel.
            </p>
            <h3 id="integrated-gradients">Appendix B: Integrated gradients for a hidden layer</h3>
            <p>
                Here we explain the application of integrated gradients <d-cite key="integratedgradients"></d-cite> to a
                hidden layer for the purpose of <a href="#attribution">attribution</a>. This method can be applied to
                any of the network’s outputs, but we focus here on the value function. Recall that this is the model’s
                estimate of the time-discounted probability that the agent will successfully complete the level.
            </p>
            <div>
                <p>
                    Let <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>V</mi>
                                            <mo>:</mo>
                                            <msup>
                                                <mi mathvariant="double-struck">R</mi>
                                                <mrow>
                                                    <mn>6</mn>
                                                    <mn>4</mn>
                                                    <mo>×</mo>
                                                    <mn>6</mn>
                                                    <mn>4</mn>
                                                    <mo>×</mo>
                                                    <mn>3</mn>
                                                </mrow>
                                            </msup>
                                            <mo>→</mo>
                                            <mi mathvariant="double-struck">R</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">V:\mathbb R^{64\times 64\times
                                            3}\to\mathbb R</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.8141079999999999em;"></span><span class="strut bottom"
                                    style="height:0.8141079999999999em;vertical-align:0em;"></span><span
                                    class="base"><span class="mord mathit" style="margin-right:0.22222em;">V</span><span
                                        class="mrel">:</span><span class="mord"><span class="mord mathbb">R</span><span
                                            class="msupsub"><span class="vlist-t"><span class="vlist-r"><span
                                                        class="vlist" style="height:0.8141079999999999em;"><span
                                                            style="top:-3.063em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mtight"><span
                                                                        class="mord mathrm mtight">6</span><span
                                                                        class="mord mathrm mtight">4</span><span
                                                                        class="mbin mtight">×</span><span
                                                                        class="mord mathrm mtight">6</span><span
                                                                        class="mord mathrm mtight">4</span><span
                                                                        class="mbin mtight">×</span><span
                                                                        class="mord mathrm mtight">3</span></span></span></span></span></span></span></span></span><span
                                        class="mrel">→</span><span
                                        class="mord mathbb">R</span></span></span></span></span> be the value function
                    computed by our network, which accepts a 64x64 RGB observation. Given any layer in the network, we
                    may write <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>V</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">V</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.68333em;"></span><span class="strut bottom"
                                    style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathit"
                                        style="margin-right:0.22222em;">V</span></span></span></span></span> as
                    <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>V</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">x</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                            <mo>=</mo>
                                            <mi>F</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">A</mi>
                                                <mrow>
                                                    <mo fence="true">(</mo>
                                                    <mi mathvariant="bold">x</mi>
                                                    <mo fence="true">)</mo>
                                                </mrow>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">V\left(\mathbf x\right)=F\left(\mathbf
                                            A\left(\mathbf x\right)\right)</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord mathit" style="margin-right:0.22222em;">V</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathbf">x</span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span><span class="mrel">=</span><span
                                        class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathbf">A</span><span class="minner"><span
                                                class="mopen delimcenter" style="top:0em;">(</span><span
                                                class="mord mathbf">x</span><span class="mclose delimcenter"
                                                style="top:0em;">)</span></span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span>, where
                    <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="bold">A</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf A</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.68611em;"></span><span class="strut bottom"
                                    style="height:0.68611em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathbf">A</span></span></span></span></span> computes the layer’s
                    activations. Given an observation <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="bold">x</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf x</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.44444em;"></span><span class="strut bottom"
                                    style="height:0.44444em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathbf">x</span></span></span></span></span>, a simple method of
                    attribution is to compute <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <msub>
                                                <mi mathvariant="normal">∇</mi>
                                                <mi mathvariant="bold">a</mi>
                                            </msub>
                                            <mi>F</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">a</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                            <mo>⊙</mo>
                                            <mi mathvariant="bold">a</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\nabla_{\mathbf a}F\left(\mathbf
                                            a\right)\odot\mathbf a</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span
                                                class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                        style="height:0.161108em;"><span
                                                            style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mtight"><span
                                                                        class="mord mathbf mtight">a</span></span></span></span></span><span
                                                        class="vlist-s">​</span></span><span class="vlist-r"><span
                                                        class="vlist"
                                                        style="height:0.15em;"></span></span></span></span></span><span
                                        class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathbf">a</span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span><span class="mbin">⊙</span><span
                                        class="mord mathbf">a</span></span></span></span></span>, where <span><span
                            class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="bold">a</mi>
                                            <mo>=</mo>
                                            <mi mathvariant="bold">A</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">x</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf a=\mathbf A\left(\mathbf
                                            x\right)</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord mathbf">a</span><span class="mrel">=</span><span
                                        class="mord mathbf">A</span><span class="minner"><span class="mopen delimcenter"
                                            style="top:0em;">(</span><span class="mord mathbf">x</span><span
                                            class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span> and <span><span
                            class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mo>⊙</mo>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\odot</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.58333em;"></span><span class="strut bottom"
                                    style="height:0.66666em;vertical-align:-0.08333em;"></span><span class="base"><span
                                        class="mord">⊙</span></span></span></span></span> denotes the pointwise product.
                    This tells us the sensitivity of the value function to each activation, multiplied by the strength
                    of that activation. However, it uses the sensitivity of the value function at the activation itself,
                    which does not account for the fact that this sensitivity may change as the activation is increased
                    from zero.
                </p>
            </div>
            <div>
                <p>
                    To account for this, the integrated gradients method instead chooses a path <span><span
                            class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="script">P</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathcal P</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.68333em;"></span><span class="strut bottom"
                                    style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathcal"
                                        style="margin-right:0.08222em;">P</span></span></span></span></span> in
                    activation space from some starting point <span><span class="katex"><span
                                class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <msub>
                                                <mi mathvariant="bold">a</mi>
                                                <mn>0</mn>
                                            </msub>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf a_0</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.44444em;"></span><span class="strut bottom"
                                    style="height:0.59444em;vertical-align:-0.15em;"></span><span class="base"><span
                                        class="mord"><span class="mord mathbf">a</span><span class="msupsub"><span
                                                class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                        style="height:0.30110799999999993em;"><span
                                                            style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mathrm mtight">0</span></span></span></span><span
                                                        class="vlist-s">​</span></span><span class="vlist-r"><span
                                                        class="vlist"
                                                        style="height:0.15em;"></span></span></span></span></span></span></span></span></span>
                    to the ending point <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <msub>
                                                <mi mathvariant="bold">a</mi>
                                                <mn>1</mn>
                                            </msub>
                                            <mo>:</mo>
                                            <mo>=</mo>
                                            <mi mathvariant="bold">A</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">x</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf a_1:=\mathbf A\left(\mathbf
                                            x\right)</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord"><span class="mord mathbf">a</span><span class="msupsub"><span
                                                class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                        style="height:0.30110799999999993em;"><span
                                                            style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mathrm mtight">1</span></span></span></span><span
                                                        class="vlist-s">​</span></span><span class="vlist-r"><span
                                                        class="vlist"
                                                        style="height:0.15em;"></span></span></span></span></span><span
                                        class="mrel">:</span><span class="mrel">=</span><span
                                        class="mord mathbf">A</span><span class="minner"><span class="mopen delimcenter"
                                            style="top:0em;">(</span><span class="mord mathbf">x</span><span
                                            class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span>. We then
                    compute the integrated gradient of <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>F</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">F</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.68333em;"></span><span class="strut bottom"
                                    style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathit"
                                        style="margin-right:0.13889em;">F</span></span></span></span></span> along
                    <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="script">P</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathcal P</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.68333em;"></span><span class="strut bottom"
                                    style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathcal"
                                        style="margin-right:0.08222em;">P</span></span></span></span></span>, which is
                    defined as the path integral <span><span class="katex-display"><span class="katex"><span
                                    class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <msub>
                                                    <mo>∫</mo>
                                                    <mi mathvariant="script">P</mi>
                                                </msub>
                                                <msub>
                                                    <mi mathvariant="normal">∇</mi>
                                                    <mi mathvariant="bold">a</mi>
                                                </msub>
                                                <mi>F</mi>
                                                <mrow>
                                                    <mo fence="true">(</mo>
                                                    <mi mathvariant="bold">a</mi>
                                                    <mo fence="true">)</mo>
                                                </mrow>
                                                <mo>⊙</mo>
                                                <mi mathvariant="normal">d</mi>
                                                <mi mathvariant="bold">a</mi>
                                                <mi mathvariant="normal">.</mi>
                                            </mrow>
                                            <annotation encoding="application/x-tex">\int_{\mathcal P}\nabla_{\mathbf
                                                a}F\left(\mathbf a\right)\odot\mathrm d\mathbf a.</annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:1.36em;"></span><span class="strut bottom"
                                        style="height:2.27195em;vertical-align:-0.9119499999999999em;"></span><span
                                        class="base"><span class="mop"><span class="mop op-symbol large-op"
                                                style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span
                                                class="msupsub"><span class="vlist-t vlist-t2"><span
                                                        class="vlist-r"><span class="vlist"
                                                            style="height:-0.433619em;"><span
                                                                style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span
                                                                    class="pstrut" style="height:2.7em;"></span><span
                                                                    class="sizing reset-size6 size3 mtight"><span
                                                                        class="mord mtight"><span
                                                                            class="mord mathcal mtight"
                                                                            style="margin-right:0.08222em;">P</span></span></span></span></span><span
                                                            class="vlist-s">​</span></span><span class="vlist-r"><span
                                                            class="vlist"
                                                            style="height:0.9119499999999999em;"></span></span></span></span></span><span
                                            class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span
                                                    class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                            style="height:0.161108em;"><span
                                                                style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                    class="pstrut" style="height:2.7em;"></span><span
                                                                    class="sizing reset-size6 size3 mtight"><span
                                                                        class="mord mtight"><span
                                                                            class="mord mathbf mtight">a</span></span></span></span></span><span
                                                            class="vlist-s">​</span></span><span class="vlist-r"><span
                                                            class="vlist"
                                                            style="height:0.15em;"></span></span></span></span></span><span
                                            class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                            class="minner"><span class="mopen delimcenter"
                                                style="top:0em;">(</span><span class="mord mathbf">a</span><span
                                                class="mclose delimcenter" style="top:0em;">)</span></span><span
                                            class="mbin">⊙</span><span class="mord mathrm">d</span><span
                                            class="mord mathbf">a</span><span
                                            class="mord mathrm">.</span></span></span></span></span></span> Note the use
                    of the pointwise product rather than the usual dot product here, which makes the integral
                    vector-valued. By the <a href="https://en.wikipedia.org/wiki/Gradient_theorem">fundamental theorem
                        of calculus for line integrals</a>, when the components of the vector produced by this integral
                    are summed, the result depends only on the endpoints <span><span class="katex"><span
                                class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <msub>
                                                <mi mathvariant="bold">a</mi>
                                                <mn>0</mn>
                                            </msub>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf a_0</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.44444em;"></span><span class="strut bottom"
                                    style="height:0.59444em;vertical-align:-0.15em;"></span><span class="base"><span
                                        class="mord"><span class="mord mathbf">a</span><span class="msupsub"><span
                                                class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                        style="height:0.30110799999999993em;"><span
                                                            style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mathrm mtight">0</span></span></span></span><span
                                                        class="vlist-s">​</span></span><span class="vlist-r"><span
                                                        class="vlist"
                                                        style="height:0.15em;"></span></span></span></span></span></span></span></span></span>
                    and <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <msub>
                                                <mi mathvariant="bold">a</mi>
                                                <mn>1</mn>
                                            </msub>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf a_1</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.44444em;"></span><span class="strut bottom"
                                    style="height:0.59444em;vertical-align:-0.15em;"></span><span class="base"><span
                                        class="mord"><span class="mord mathbf">a</span><span class="msupsub"><span
                                                class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                        style="height:0.30110799999999993em;"><span
                                                            style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mathrm mtight">1</span></span></span></span><span
                                                        class="vlist-s">​</span></span><span class="vlist-r"><span
                                                        class="vlist"
                                                        style="height:0.15em;"></span></span></span></span></span></span></span></span></span>,
                    equaling <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>F</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <msub>
                                                    <mi mathvariant="bold">a</mi>
                                                    <mn>1</mn>
                                                </msub>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                            <mo>−</mo>
                                            <mi>F</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <msub>
                                                    <mi mathvariant="bold">a</mi>
                                                    <mn>0</mn>
                                                </msub>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">F\left(\mathbf
                                            a_1\right)-F\left(\mathbf a_0\right)</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord"><span class="mord mathbf">a</span><span class="msupsub"><span
                                                    class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                            style="height:0.30110799999999993em;"><span
                                                                style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                    class="pstrut" style="height:2.7em;"></span><span
                                                                    class="sizing reset-size6 size3 mtight"><span
                                                                        class="mord mathrm mtight">1</span></span></span></span><span
                                                            class="vlist-s">​</span></span><span class="vlist-r"><span
                                                            class="vlist"
                                                            style="height:0.15em;"></span></span></span></span></span><span
                                            class="mclose delimcenter" style="top:0em;">)</span></span><span
                                        class="mbin">−</span><span class="mord mathit"
                                        style="margin-right:0.13889em;">F</span><span class="minner"><span
                                            class="mopen delimcenter" style="top:0em;">(</span><span class="mord"><span
                                                class="mord mathbf">a</span><span class="msupsub"><span
                                                    class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                            style="height:0.30110799999999993em;"><span
                                                                style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                    class="pstrut" style="height:2.7em;"></span><span
                                                                    class="sizing reset-size6 size3 mtight"><span
                                                                        class="mord mathrm mtight">0</span></span></span></span><span
                                                            class="vlist-s">​</span></span><span class="vlist-r"><span
                                                            class="vlist"
                                                            style="height:0.15em;"></span></span></span></span></span><span
                                            class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span>. Thus the
                    components of this vector provide a true decomposition of this difference, “attributing” it across
                    the activations.
                </p>
                <p style="margin-bottom: 0;">
                    For our purposes, we take <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="script">P</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathcal P</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.68333em;"></span><span class="strut bottom"
                                    style="height:0.68333em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathcal"
                                        style="margin-right:0.08222em;">P</span></span></span></span></span> to be the
                    straight line from <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mn mathvariant="bold">0</mn>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf 0</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.64444em;"></span><span class="strut bottom"
                                    style="height:0.64444em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathbf">0</span></span></span></span></span> to <span><span
                            class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="bold">A</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">x</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf A\left(\mathbf x\right)
                                        </annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord mathbf">A</span><span class="minner"><span class="mopen delimcenter"
                                            style="top:0em;">(</span><span class="mord mathbf">x</span><span
                                            class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span>.<d-footnote
                        id="d-footnote-19">In theory, we could choose any point in activation space as the starting
                        point of our path, but in practice, <span><span class="katex"><span class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mn mathvariant="bold">0</mn>
                                            </mrow>
                                            <annotation encoding="application/x-tex">\mathbf 0</annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.64444em;"></span><span class="strut bottom"
                                        style="height:0.64444em;vertical-align:0em;"></span><span class="base"><span
                                            class="mord mathbf">0</span></span></span></span></span> tends to be a good
                        baseline against which to compare other activations, with <span><span class="katex"><span
                                    class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mi>F</mi>
                                                <mrow>
                                                    <mo fence="true">(</mo>
                                                    <mn mathvariant="bold">0</mn>
                                                    <mo fence="true">)</mo>
                                                </mrow>
                                            </mrow>
                                            <annotation encoding="application/x-tex">F\left(\mathbf 0\right)
                                            </annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.75em;"></span><span class="strut bottom"
                                        style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                            class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                            class="minner"><span class="mopen delimcenter"
                                                style="top:0em;">(</span><span class="mord mathbf">0</span><span
                                                class="mclose delimcenter"
                                                style="top:0em;">)</span></span></span></span></span></span> being on
                        the same order as the average value function. Sundararajan, Taly and Yan <d-cite
                            key="integratedgradients"></d-cite> discuss the choice of this baseline in more depth.
                    </d-footnote> In other words, given an observation <span><span class="katex"><span
                                class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="bold">x</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf x</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.44444em;"></span><span class="strut bottom"
                                    style="height:0.44444em;vertical-align:0em;"></span><span class="base"><span
                                        class="mord mathbf">x</span></span></span></span></span>, we define the value
                    function attribution as<d-footnote id="d-footnote-20">In practice, we numerically approximate the
                        integral by evaluating the integrand at <span><span class="katex"><span
                                    class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mi>α</mi>
                                                <mo>=</mo>
                                                <mn>0</mn>
                                                <mi mathvariant="normal">.</mi>
                                                <mn>1</mn>
                                                <mo separator="true">,</mo>
                                                <mn>0</mn>
                                                <mi mathvariant="normal">.</mi>
                                                <mn>2</mn>
                                                <mo separator="true">,</mo>
                                                <mo>…</mo>
                                                <mo separator="true">,</mo>
                                                <mn>1</mn>
                                            </mrow>
                                            <annotation encoding="application/x-tex">\alpha=0.1,0.2,\ldots,1
                                            </annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.64444em;"></span><span class="strut bottom"
                                        style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span
                                        class="base"><span class="mord mathit"
                                            style="margin-right:0.0037em;">α</span><span class="mrel">=</span><span
                                            class="mord mathrm">0</span><span class="mord mathrm">.</span><span
                                            class="mord mathrm">1</span><span class="mpunct">,</span><span
                                            class="mord mathrm">0</span><span class="mord mathrm">.</span><span
                                            class="mord mathrm">2</span><span class="mpunct">,</span><span
                                            class="minner">…</span><span class="mpunct">,</span><span
                                            class="mord mathrm">1</span></span></span></span></span>.</d-footnote>
                </p>
                <span><span class="katex-display"><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <msubsup>
                                                <mo>∫</mo>
                                                <mrow>
                                                    <mi>α</mi>
                                                    <mo>=</mo>
                                                    <mn>0</mn>
                                                </mrow>
                                                <mn>1</mn>
                                            </msubsup>
                                            <msub>
                                                <mi mathvariant="normal">∇</mi>
                                                <mi mathvariant="bold">a</mi>
                                            </msub>
                                            <mi>F</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi>α</mi>
                                                <mi mathvariant="bold">A</mi>
                                                <mrow>
                                                    <mo fence="true">(</mo>
                                                    <mi mathvariant="bold">x</mi>
                                                    <mo fence="true">)</mo>
                                                </mrow>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                            <mi mathvariant="normal">d</mi>
                                            <mi>α</mi>
                                            <mo>⊙</mo>
                                            <mi mathvariant="bold">A</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">x</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                            <mi mathvariant="normal">.</mi>
                                        </mrow>
                                        <annotation encoding="application/x-tex">
                                            \int_{\alpha=0}^1\nabla_{\mathbf a}F\left(\alpha\mathbf A\left(\mathbf
                                            x\right)\right)\mathrm d\alpha\odot\mathbf A\left(\mathbf x\right).
                                        </annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:1.5640080000000003em;"></span><span class="strut bottom"
                                    style="height:2.4759580000000003em;vertical-align:-0.9119499999999999em;"></span><span
                                    class="base"><span class="mop"><span class="mop op-symbol large-op"
                                            style="margin-right:0.44445em;position:relative;top:-0.0011249999999999316em;">∫</span><span
                                            class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span
                                                        class="vlist" style="height:1.5640080000000003em;"><span
                                                            style="top:-1.7880500000000001em;margin-left:-0.44445em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mtight"><span class="mord mathit mtight"
                                                                        style="margin-right:0.0037em;">α</span><span
                                                                        class="mrel mtight">=</span><span
                                                                        class="mord mathrm mtight">0</span></span></span></span><span
                                                            style="top:-3.8129000000000004em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mathrm mtight">1</span></span></span></span><span
                                                        class="vlist-s">​</span></span><span class="vlist-r"><span
                                                        class="vlist"
                                                        style="height:0.9119499999999999em;"></span></span></span></span></span><span
                                        class="mord"><span class="mord mathrm">∇</span><span class="msupsub"><span
                                                class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist"
                                                        style="height:0.161108em;"><span
                                                            style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span
                                                                class="pstrut" style="height:2.7em;"></span><span
                                                                class="sizing reset-size6 size3 mtight"><span
                                                                    class="mord mtight"><span
                                                                        class="mord mathbf mtight">a</span></span></span></span></span><span
                                                        class="vlist-s">​</span></span><span class="vlist-r"><span
                                                        class="vlist"
                                                        style="height:0.15em;"></span></span></span></span></span><span
                                        class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathit" style="margin-right:0.0037em;">α</span><span
                                            class="mord mathbf">A</span><span class="minner"><span
                                                class="mopen delimcenter" style="top:0em;">(</span><span
                                                class="mord mathbf">x</span><span class="mclose delimcenter"
                                                style="top:0em;">)</span></span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span><span class="mord mathrm">d</span><span
                                        class="mord mathit" style="margin-right:0.0037em;">α</span><span
                                        class="mbin">⊙</span><span class="mord mathbf">A</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathbf">x</span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span><span
                                        class="mord mathrm">.</span></span></span></span></span></span>
                <p>
                    This has the same dimensions as <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi mathvariant="bold">A</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">x</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">\mathbf A\left(\mathbf x\right)
                                        </annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord mathbf">A</span><span class="minner"><span class="mopen delimcenter"
                                            style="top:0em;">(</span><span class="mord mathbf">x</span><span
                                            class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span>, and its
                    components sum to <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>V</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mi mathvariant="bold">x</mi>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                            <mo>−</mo>
                                            <mi>F</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mn mathvariant="bold">0</mn>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">V\left(\mathbf x\right)-F\left(\mathbf
                                            0\right)</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord mathit" style="margin-right:0.22222em;">V</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathbf">x</span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span><span class="mbin">−</span><span
                                        class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathbf">0</span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span>. So for a
                    convolutional layer, this method allows us to attribute the value function (in excess of the
                    baseline <span><span class="katex"><span class="katex-mathml"><math>
                                    <semantics>
                                        <mrow>
                                            <mi>F</mi>
                                            <mrow>
                                                <mo fence="true">(</mo>
                                                <mn mathvariant="bold">0</mn>
                                                <mo fence="true">)</mo>
                                            </mrow>
                                        </mrow>
                                        <annotation encoding="application/x-tex">F\left(\mathbf 0\right)</annotation>
                                    </semantics>
                                </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                    style="height:0.75em;"></span><span class="strut bottom"
                                    style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                        class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                        class="minner"><span class="mopen delimcenter" style="top:0em;">(</span><span
                                            class="mord mathbf">0</span><span class="mclose delimcenter"
                                            style="top:0em;">)</span></span></span></span></span></span>) across the
                    horizontal, vertical and channel dimensions of activation space. Positive value function attribution
                    can be thought of as “good news”, components that cause the agent to think it is more likely to
                    collect the coin at the end of the level. Similarly, negative value function attribution can be
                    thought of as “bad news”.
                </p>
            </div>
            <h3 id="architecture">Appendix C: Architecture</h3>
            <p>
                Our architecture consists of the following layers in the order given, together with ReLU activations for
                all except the final layer.
            </p>
            <ul class="architecture-list">
                <li>7x7 convolutional layer with 16 channels (layer 1a)</li>
                <li>2x2 L2 pooling layer</li>
                <li>5x5 convolutional layer with 32 channels (layer 2a)</li>
                <li>5x5 convolutional layer with 32 channels (layer 2b)</li>
                <li>2x2 L2 pooling layer</li>
                <li>5x5 convolutional layer with 32 channels (layer 3a)</li>
                <li>2x2 L2 pooling layer</li>
                <li>5x5 convolutional layer with 32 channels (layer 4a)</li>
                <li>2x2 L2 pooling layer</li>
                <li>256-unit dense layer</li>
                <li>512-unit dense layer</li>
                <li>10-unit dense layer (1 unit for the value function, 9 units for the policy logits)</li>
            </ul>
            <p>
                We designed this architecture by starting with the architecture from IMPALA <d-cite key="impala">
                </d-cite>, and making the following modifications in an attempt to aid interpretability without
                noticeably sacrificing performance.
            </p>
            <ul class="architecture-list">
                <li>We used fewer convolutional layers and more dense layers, to allow for more non-visual processing.
                </li>
                <li>We removed the residual connections, so that the flow of information passes through every layer.
                </li>
                <li>We made the pool size equal to the pool stride, to avoid gradient gridding.</li>
                <li>We used L2 pooling instead of max pooling, for more continuous gradients.</li>
            </ul>
            <p>
                The choice that seemed to make the most difference was using 5 rather than 12 convolutional layers,
                resulting in the object-identifying features (which were the most interpretable, as discussed <a
                    href="#diversity-hypothesis">above</a>) being concentrated in a single layer (layer 2b), rather than
                being spread over multiple layers and mixed in with less interpretable features.
            </p>
            <h3>Acknowledgments</h3>
            <p>
                We would like to thank our reviewers Jonathan Uesato, Joel Lehman and one anonymous reviewer for their
                detailed and thoughtful feedback. We would also like to thank Karl Cobbe, Daniel Filan, Sam Greydanus,
                Christopher Hesse, Jacob Jackson, Michael Littman, Ben Millwood, Konstantinos Mitsopoulos, Mira Murati,
                Jorge Orbay, Alex Ray, Ludwig Schubert, John Schulman, Ilya Sutskever, Nevan Wichers, Liang Zhang and
                Daniel Ziegler for research discussions, feedback, follow-up work, help and support that have greatly
                benefited this project.
            </p>

            <h3>Author Contributions</h3>
            <p>
                <b>Jacob Hilton</b> was the primary contributor.
            </p>
            <p>
                <b>Nick Cammarata</b> developed the model editing methodology and suggested applying it to CoinRun
                models.
            </p>
            <p>
                <b>Shan Carter</b> (while working at OpenAI) advised on interface design throughout the project, and
                worked on many of the diagrams in the article.
            </p>
            <p>
                <b>Gabriel Goh</b> provided evaluations of feature interpretability for the section <a
                    href="#interpretability-and-generalization">Interpretability and generalization</a>.
            </p>
            <p>
                <b>Chris Olah</b> guided the direction of the project, performing initial exploratory research on the
                models, coming up with many of the research ideas, and helping to construct the article’s narrative.
            </p>

            <h3>Discussion and Review</h3>
            <p>
                <a href="https://github.com/distillpub/post--understanding-rl-vision/issues/6">Review 1 -
                    Anonymous</a><br>
                <a href="https://github.com/distillpub/post--understanding-rl-vision/issues/7">Review 2 - Jonathan
                    Uesato</a><br>
                <a href="https://github.com/distillpub/post--understanding-rl-vision/issues/8">Review 3 - Joel
                    Lehman</a><br>
            </p>

            <d-footnote-list style="">
                <style>
                    d-footnote-list {
                        contain: layout style;
                    }

                    d-footnote-list>* {
                        grid-column: text;
                    }

                    d-footnote-list a.footnote-backlink {
                        color: rgba(0, 0, 0, 0.3);
                        padding-left: 0.5em;
                    }
                </style>

                <h3>Footnotes</h3>
                <ol>
                    <li id="d-footnote-1-listing">We use the original version of CoinRun <d-cite key="coinrunpaper">
                        </d-cite>, not the version from Procgen Benchmark <d-cite key="procgen"></d-cite>, which is
                        slightly different. To play CoinRun yourself, please follow the instructions <a
                            href="https://github.com/openai/coinrun">here</a>.<a class="footnote-backlink"
                            href="#d-footnote-1">[↩]</a></li>
                    <li id="d-footnote-2-listing">Painting in the velocity info allows the model to infer the agent’s
                        motion from a single frame. The shade of the left square indicates the agent’s horizontal
                        velocity (black for left at full speed, white for right at full speed), and the shade of the
                        right square indicates the agent’s vertical velocity (black for down at full speed, white for up
                        at full speed). In this example, the agent is moving forward and about to land (and is thus
                        moving right and down).<a class="footnote-backlink" href="#d-footnote-2">[↩]</a></li>
                    <li id="d-footnote-3-listing">The original version of CoinRun only has 1 “do nothing” action, but
                        our version ended up with 3 when “A” and “B” actions were added to be used in other games. For
                        consistency, we have relabeled the original “do nothing” action as “C”.<a
                            class="footnote-backlink" href="#d-footnote-3">[↩]</a></li>
                    <li id="d-footnote-4-listing">We used the standard PPO hyperparameters for CoinRun <d-cite
                            key="coinrunpaper"></d-cite>, except that we used twice as many copies of the environment
                        per worker and twice and many workers. The effect of these changes was to increase the effective
                        batch size, which seemed to be necessary to reach the same performance with our smaller
                        architecture.<a class="footnote-backlink" href="#d-footnote-4">[↩]</a></li>
                    <li id="d-footnote-5-listing">We use a discount rate of 0.999 per timestep.<a
                            class="footnote-backlink" href="#d-footnote-5">[↩]</a></li>
                    <li id="d-footnote-6-listing">We use the same GAE hyperparameters as in training, namely <span><span
                                class="katex"><span class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mi>γ</mi>
                                                <mo>=</mo>
                                                <mn>0</mn>
                                                <mi mathvariant="normal">.</mi>
                                                <mn>9</mn>
                                                <mn>9</mn>
                                                <mn>9</mn>
                                            </mrow>
                                            <annotation encoding="application/x-tex">\gamma=0.999</annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.64444em;"></span><span class="strut bottom"
                                        style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span
                                        class="base"><span class="mord mathit"
                                            style="margin-right:0.05556em;">γ</span><span class="mrel">=</span><span
                                            class="mord mathrm">0</span><span class="mord mathrm">.</span><span
                                            class="mord mathrm">9</span><span class="mord mathrm">9</span><span
                                            class="mord mathrm">9</span></span></span></span></span> and <span><span
                                class="katex"><span class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mi>λ</mi>
                                                <mo>=</mo>
                                                <mn>0</mn>
                                                <mi mathvariant="normal">.</mi>
                                                <mn>9</mn>
                                                <mn>5</mn>
                                            </mrow>
                                            <annotation encoding="application/x-tex">\lambda=0.95</annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.69444em;"></span><span class="strut bottom"
                                        style="height:0.69444em;vertical-align:0em;"></span><span class="base"><span
                                            class="mord mathit">λ</span><span class="mrel">=</span><span
                                            class="mord mathrm">0</span><span class="mord mathrm">.</span><span
                                            class="mord mathrm">9</span><span
                                            class="mord mathrm">5</span></span></span></span></span>.<a
                            class="footnote-backlink" href="#d-footnote-6">[↩]</a></li>
                    <li id="d-footnote-7-listing">The data for this plot are as follows.<br>Percentage of levels failed
                        due to: buzzsaw obstacle / enemy moving left / enemy moving right / multiple or other:<br>-
                        Original model: 0.37% / 0.16% / 0.12% / 0.08%<br>- Buzzsaw obstacle blindness: 12.76% / 0.16% /
                        0.08% / 0.05%<br>- Enemy moving left blindness: 0.36% / 4.69% / 0.97% / 0.07%<br>Each model was
                        tested on 10,000 levels.<a class="footnote-backlink" href="#d-footnote-7">[↩]</a></li>
                    <li id="d-footnote-8-listing">Our results on the version of the game with invisible buzzsaws are as
                        follows.<br>Percentage of levels failed due to: buzzsaw obstacle / enemy moving left / enemy
                        moving right / multiple or other:<br>Original model, invisible buzzsaws: 32.20% / 0.05% / 0.05%
                        / 0.05%<br>We tested the model on 10,000 levels.<br>We experimented briefly with iterating the
                        editing procedure, but were not able to achieve more than around 50% buzzsaw blindness by this
                        metric without affecting the model’s other abilities.<a class="footnote-backlink"
                            href="#d-footnote-8">[↩]</a></li>
                    <li id="d-footnote-9-listing">The interfaces used for this evaluation can be found <a
                            href="https://openaipublic.blob.core.windows.net/rl-clarity/attribution/finite_levels/index.html">here</a>.<a
                            class="footnote-backlink" href="#d-footnote-9">[↩]</a></li>
                    <li id="d-footnote-10-listing">The data for this plot are as follows.<br>- Number of training
                        levels: 100 / 300 / 1000 / 3,000 / 10,000 / 30,000 / 100,000<br>- Percentage of levels completed
                        (train, run 1): 99.96% / 99.82% / 99.67% / 99.65% / 99.47% / 99.55% / 99.57%<br>- Percentage of
                        levels completed (train, run 2): 99.97% / 99.86% / 99.70% / 99.46% / 99.39% / 99.50% /
                        99.37%<br>- Percentage of levels completed (test, run 1): 61.81% / 66.95% / 74.93% / 89.87% /
                        97.53% / 98.66% / 99.25%<br>- Percentage of levels completed (test, run 2): 64.13% / 67.64% /
                        73.46% / 90.36% / 97.44% / 98.89% / 99.35%<br>- Percentage of features interpretable (researcher
                        1, run 1): 52.5% / 22.5% / 11.25% / 45% / 90% / 75% / 91.25%<br>- Percentage of features
                        interpretable (researcher 2, run 1): 8.75% / 8.75% / 10% / 26.25% / 56.25% / 90% / 70%<br>-
                        Percentage of features interpretable (researcher 1, run 2): 15% / 13.75% / 15% / 23.75% / 53.75%
                        / 90% / 96.25%<br>- Percentage of features interpretable (researcher 2, run 2): 3.75% / 6.25% /
                        21.25% / 45% / 72.5% / 83.75% / 77.5%<br>Percentages of levels completed are estimated by
                        sampling 10,000 levels with replacement.<a class="footnote-backlink"
                            href="#d-footnote-10">[↩]</a></li>
                    <li id="d-footnote-11-listing">Our methodology had some flaws. Firstly, the researchers were not
                        completely blind to the number of levels: for example, it is possible to infer something about
                        the number of levels from the smoothness of graphs of the value function, since with fewer
                        levels the model is better able to memorize the number of timesteps until the end of the level.
                        Secondly, since evaluations are somewhat tedious, we stopped them once we thought the trend had
                        become clear, introducing some selection bias. Therefore these results should be considered
                        primarily illustrative.<a class="footnote-backlink" href="#d-footnote-11">[↩]</a></li>
                    <li id="d-footnote-12-listing">By an “extremal” color we mean one of the 8 colors with maximal or
                        minimal RGB values (black, white, red, green, blue, yellow, cyan and magenta).<a
                            class="footnote-backlink" href="#d-footnote-12">[↩]</a></li>
                    <li id="d-footnote-13-listing">The caricature objective is to maximize the dot product between the
                        activations of the input image and the activations of a reference image. Caricatures are often
                        an especially easy type of feature visualization to make work, and helpful for getting a first
                        glance into what features a model has. They are demonstrated in <a
                            href="https://colab.research.google.com/github/tensorflow/lucid/blob/master/notebooks/misc/feature_inversion_caricatures.ipynb">this
                            notebook</a>. A more detailed manuscript by its authors <d-cite key="caricatures"></d-cite>
                        is forthcoming.<a class="footnote-backlink" href="#d-footnote-13">[↩]</a></li>
                    <li id="d-footnote-14-listing">More precisely, we find a non-negative approximate low-rank
                        factorization of the matrix obtained by flattening the spatial dimensions of the activations
                        into the batch dimension. This matrix has one row per observation <i>per spatial position</i>
                        and one column per channel: thus the dimensionality reduction does not use spatial
                        information.<a class="footnote-backlink" href="#d-footnote-14">[↩]</a></li>
                    <li id="d-footnote-15-listing">As before, we obtain the NMF directions by sampling a few thousand
                        observations infrequently from the agent playing the game, computing the attributions,
                        flattening the spatial dimensions into the batch dimension, and applying NMF.<a
                            class="footnote-backlink" href="#d-footnote-15">[↩]</a></li>
                    <li id="d-footnote-16-listing">Our workaround is to separate out the positive and negative parts of
                        the attributions and concatenate them along the batch dimension. We could also have concatenated
                        them along the channel dimension.<a class="footnote-backlink" href="#d-footnote-16">[↩]</a></li>
                    <li id="d-footnote-17-listing">For example, to measure generalization for CoinRun models trained on
                        a limited number of levels, we used the distribution over all possible procedurally-generated
                        levels. However, to formalize the sense in which CoinRun is not diverse in its visual patterns
                        or dynamics rules, one would need a distribution over levels from a wider class of games.<a
                            class="footnote-backlink" href="#d-footnote-17">[↩]</a></li>
                    <li id="d-footnote-18-listing">Heavily-regularized feature visualization may be untrustworthy by
                        failing to separate the things causing certain behavior from the things that merely correlate
                        with those causes <d-cite key="featurevis"></d-cite>.<a class="footnote-backlink"
                            href="#d-footnote-18">[↩]</a></li>
                    <li id="d-footnote-19-listing">In theory, we could choose any point in activation space as the
                        starting point of our path, but in practice, <span><span class="katex"><span
                                    class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mn mathvariant="bold">0</mn>
                                            </mrow>
                                            <annotation encoding="application/x-tex">\mathbf 0</annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.64444em;"></span><span class="strut bottom"
                                        style="height:0.64444em;vertical-align:0em;"></span><span class="base"><span
                                            class="mord mathbf">0</span></span></span></span></span> tends to be a good
                        baseline against which to compare other activations, with <span><span class="katex"><span
                                    class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mi>F</mi>
                                                <mrow>
                                                    <mo fence="true">(</mo>
                                                    <mn mathvariant="bold">0</mn>
                                                    <mo fence="true">)</mo>
                                                </mrow>
                                            </mrow>
                                            <annotation encoding="application/x-tex">F\left(\mathbf 0\right)
                                            </annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.75em;"></span><span class="strut bottom"
                                        style="height:1em;vertical-align:-0.25em;"></span><span class="base"><span
                                            class="mord mathit" style="margin-right:0.13889em;">F</span><span
                                            class="minner"><span class="mopen delimcenter"
                                                style="top:0em;">(</span><span class="mord mathbf">0</span><span
                                                class="mclose delimcenter"
                                                style="top:0em;">)</span></span></span></span></span></span> being on
                        the same order as the average value function. Sundararajan, Taly and Yan <d-cite
                            key="integratedgradients"></d-cite> discuss the choice of this baseline in more depth.<a
                            class="footnote-backlink" href="#d-footnote-19">[↩]</a></li>
                    <li id="d-footnote-20-listing">In practice, we numerically approximate the integral by evaluating
                        the integrand at <span><span class="katex"><span class="katex-mathml"><math>
                                        <semantics>
                                            <mrow>
                                                <mi>α</mi>
                                                <mo>=</mo>
                                                <mn>0</mn>
                                                <mi mathvariant="normal">.</mi>
                                                <mn>1</mn>
                                                <mo separator="true">,</mo>
                                                <mn>0</mn>
                                                <mi mathvariant="normal">.</mi>
                                                <mn>2</mn>
                                                <mo separator="true">,</mo>
                                                <mo>…</mo>
                                                <mo separator="true">,</mo>
                                                <mn>1</mn>
                                            </mrow>
                                            <annotation encoding="application/x-tex">\alpha=0.1,0.2,\ldots,1
                                            </annotation>
                                        </semantics>
                                    </math></span><span class="katex-html" aria-hidden="true"><span class="strut"
                                        style="height:0.64444em;"></span><span class="strut bottom"
                                        style="height:0.8388800000000001em;vertical-align:-0.19444em;"></span><span
                                        class="base"><span class="mord mathit"
                                            style="margin-right:0.0037em;">α</span><span class="mrel">=</span><span
                                            class="mord mathrm">0</span><span class="mord mathrm">.</span><span
                                            class="mord mathrm">1</span><span class="mpunct">,</span><span
                                            class="mord mathrm">0</span><span class="mord mathrm">.</span><span
                                            class="mord mathrm">2</span><span class="mpunct">,</span><span
                                            class="minner">…</span><span class="mpunct">,</span><span
                                            class="mord mathrm">1</span></span></span></span></span>.<a
                            class="footnote-backlink" href="#d-footnote-20">[↩]</a></li>
                </ol>
            </d-footnote-list>
            <d-citation-list distill-prerendered="true">
                <style>
                    d-citation-list {
                        contain: style;
                    }

                    d-citation-list .references {
                        grid-column: text;
                    }

                    d-citation-list .references .title {
                        font-weight: 500;
                    }
                </style>
                <h3 id="references">References</h3>
                <ol id="references-list" class="references">
                    <li id="coinrunpaper"><span class="title">Quantifying generalization in reinforcement
                            learning</span>  <a
                            href="https://openai.com/blog/quantifying-generalization-in-reinforcement-learning/">[link]</a><br>Cobbe,
                        K., Klimov, O., Hesse, C., Kim, T. and Schulman, J., 2018. arXiv preprint arXiv:1812.02341.
                    </li>
                    <li id="attribution1"><span class="title">Deep inside convolutional networks: Visualising image
                            classification models and saliency maps</span>  <a
                            href="https://arxiv.org/pdf/1312.6034.pdf">[PDF]</a><br>Simonyan, K., Vedaldi, A. and
                        Zisserman, A., 2013. arXiv preprint arXiv:1312.6034. </li>
                    <li id="attribution2"><span class="title">Visualizing and understanding convolutional
                            networks</span>  <a href="https://arxiv.org/pdf/1311.2901.pdf">[PDF]</a><br>Zeiler, M.D. and
                        Fergus, R., 2014. European conference on computer vision, pp. 818--833. </li>
                    <li id="attribution3"><span class="title">Striving for simplicity: The all convolutional net</span>
                         <a href="https://arxiv.org/pdf/1412.6806.pdf">[PDF]</a><br>Springenberg, J.T., Dosovitskiy, A.,
                        Brox, T. and Riedmiller, M., 2014. arXiv preprint arXiv:1412.6806. </li>
                    <li id="gradcam"><span class="title">Grad-CAM: Visual explanations from deep networks via
                            gradient-based localization</span>  <a
                            href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf">[PDF]</a><br>Selvaraju,
                        R.R., Cogswell, M., Das, A., Vedantam, R., Parikh, D. and Batra, D., 2017. Proceedings of the
                        IEEE International Conference on Computer Vision, pp. 618--626. </li>
                    <li id="attribution4"><span class="title">Interpretable explanations of black boxes by meaningful
                            perturbation</span>  <a
                            href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Fong_Interpretable_Explanations_of_ICCV_2017_paper.pdf">[PDF]</a><br>Fong,
                        R.C. and Vedaldi, A., 2017. Proceedings of the IEEE International Conference on Computer Vision,
                        pp. 3429--3437. </li>
                    <li id="attribution5"><span class="title">PatternNet and PatternLRP--Improving the interpretability
                            of neural networks</span>  <a
                            href="https://arxiv.org/pdf/1705.05598.pdf">[PDF]</a><br>Kindermans, P., Schutt, K.T.,
                        Alber, M., Muller, K. and Dahne, S., 2017. stat, Vol 1050, pp. 16. </li>
                    <li id="attribution6"><span class="title">The (un)reliability of saliency methods</span>  <a
                            href="https://arxiv.org/pdf/1711.00867.pdf">[PDF]</a><br>Kindermans, P., Hooker, S.,
                        Adebayo, J., Alber, M., Schutt, K.T., Dahne, S., Erhan, D. and Kim, B., 2019. Explainable AI:
                        Interpreting, Explaining and Visualizing Deep Learning, pp. 267--280. Springer.</li>
                    <li id="integratedgradients"><span class="title">Axiomatic attribution for deep networks</span>  <a
                            href="https://arxiv.org/pdf/1703.01365.pdf">[PDF]</a><br>Sundararajan, M., Taly, A. and Yan,
                        Q., 2017. Proceedings of the 34th International Conference on Machine Learning-Volume 70, pp.
                        3319--3328. </li>
                    <li id="buildingblocks"><span class="title">The Building Blocks of Interpretability</span> <br>Olah,
                        C., Satyanarayan, A., Johnson, I., Carter, S., Schubert, L., Ye, K. and Mordvintsev, A., 2018.
                        Distill. <a href="https://doi.org/10.23915/distill.00010" style="text-decoration:inherit;">DOI:
                            10.23915/distill.00010</a></li>
                    <li id="procgen"><span class="title">Leveraging Procedural Generation to Benchmark Reinforcement
                            Learning</span>  <a href="https://openai.com/blog/procgen-benchmark/">[link]</a><br>Cobbe,
                        K., Hesse, C., Hilton, J. and Schulman, J., 2019. </li>
                    <li id="ppo"><span class="title">Proximal policy optimization algorithms</span>  <a
                            href="https://openai.com/blog/openai-baselines-ppo/">[link]</a><br>Schulman, J., Wolski, F.,
                        Dhariwal, P., Radford, A. and Klimov, O., 2017. arXiv preprint arXiv:1707.06347. </li>
                    <li id="gae"><span class="title">High-dimensional continuous control using generalized advantage
                            estimation</span>  <a href="https://arxiv.org/pdf/1506.02438.pdf">[PDF]</a><br>Schulman, J.,
                        Moritz, P., Levine, S., Jordan, M. and Abbeel, P., 2015. arXiv preprint arXiv:1506.02438. </li>
                    <li id="circuits"><span class="title">Thread: Circuits</span> <br>Cammarata, N., Carter, S., Goh,
                        G., Olah, C., Petrov, M. and Schubert, L., 2020. Distill. <a
                            href="https://doi.org/10.23915/distill.00024" style="text-decoration:inherit;">DOI:
                            10.23915/distill.00024</a></li>
                    <li id="gvgai"><span class="title">General Video Game AI: A multi-track framework for evaluating
                            agents, games and content generation algorithms</span>  <a
                            href="https://arxiv.org/pdf/1802.10363">[link]</a><br>Perez-Liebana, D., Liu, J., Khalifa,
                        A., Gaina, R.D., Togelius, J. and Lucas, S.M., 2018. arXiv preprint arXiv:1802.10363. </li>
                    <li id="obstacletower"><span class="title">Obstacle Tower: A Generalization Challenge in Vision,
                            Control, and Planning</span>  <a
                            href="https://arxiv.org/pdf/1902.01378.pdf">[PDF]</a><br>Juliani, A., Khalifa, A., Berges,
                        V., Harper, J., Henry, H., Crespi, A., Togelius, J. and Lange, D., 2019. arXiv preprint
                        arXiv:1902.01378. </li>
                    <li id="sonicsaliency"><span class="title">Observational Overfitting in Reinforcement
                            Learning</span>  <a href="https://arxiv.org/pdf/1912.02975.pdf">[PDF]</a><br>Song, X.,
                        Jiang, Y., Du, Y. and Neyshabur, B., 2019. arXiv preprint arXiv:1912.02975. </li>
                    <li id="featurevis"><span class="title">Feature Visualization</span> <br>Olah, C., Mordvintsev, A.
                        and Schubert, L., 2017. Distill. <a href="https://doi.org/10.23915/distill.00007"
                            style="text-decoration:inherit;">DOI: 10.23915/distill.00007</a></li>
                    <li id="featurevis1"><span class="title">Visualizing higher-layer features of a deep network</span>
                         <a
                            href="https://www.researchgate.net/profile/Aaron_Courville/publication/265022827_Visualizing_Higher-Layer_Features_of_a_Deep_Network/links/53ff82b00cf24c81027da530.pdf">[PDF]</a><br>Erhan,
                        D., Bengio, Y., Courville, A. and Vincent, P., 2009. University of Montreal, Vol 1341(3), pp. 1.
                    </li>
                    <li id="featurevis2"><span class="title">Deep neural networks are easily fooled: High confidence
                            predictions for unrecognizable images</span>  <a
                            href="https://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Nguyen_Deep_Neural_Networks_2015_CVPR_paper.pdf">[PDF]</a><br>Nguyen,
                        A., Yosinski, J. and Clune, J., 2015. Proceedings of the IEEE conference on computer vision and
                        pattern recognition, pp. 427--436. </li>
                    <li id="featurevis3"><span class="title">Inceptionism: Going deeper into neural networks</span>  <a
                            href="https://research.googleblog.com/2015/06/inceptionism-going-deeper-into-neural.html">[HTML]</a><br>Mordvintsev,
                        A., Olah, C. and Tyka, M., 2015. Google Research Blog. </li>
                    <li id="featurevis4"><span class="title">Plug &amp; play generative networks: Conditional iterative
                            generation of images in latent space</span>  <a
                            href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Nguyen_Plug__Play_CVPR_2017_paper.pdf">[PDF]</a><br>Nguyen,
                        A., Clune, J., Bengio, Y., Dosovitskiy, A. and Yosinski, J., 2017. Proceedings of the IEEE
                        Conference on Computer Vision and Pattern Recognition, pp. 4467--4477. </li>
                    <li id="imagenet"><span class="title">Imagenet: A large-scale hierarchical image database</span>  <a
                            href="http://www.image-net.org/papers/imagenet_cvpr09.pdf">[PDF]</a><br>Deng, J., Dong, W.,
                        Socher, R., Li, L., Li, K. and Fei-Fei, L., 2009. Computer Vision and Pattern Recognition, 2009.
                        CVPR 2009. IEEE Conference on, pp. 248--255. <a
                            href="https://doi.org/10.1109/cvprw.2009.5206848" style="text-decoration:inherit;">DOI:
                            10.1109/cvprw.2009.5206848</a></li>
                    <li id="googlenet"><span class="title">Going deeper with convolutions</span>  <a
                            href="https://arxiv.org/pdf/1409.4842.pdf">[PDF]</a><br>Szegedy, C., Liu, W., Jia, Y.,
                        Sermanet, P., Reed, S., Anguelov, D., Erhan, D., Vanhoucke, V. and Rabinovich, A., 2015.
                        Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 1--9. </li>
                    <li id="atarimodelzoo"><span class="title">An Atari model zoo for analyzing, visualizing, and
                            comparing deep reinforcement learning agents</span>  <a
                            href="https://arxiv.org/pdf/1812.07069.pdf">[PDF]</a><br>Such, F.P., Madhavan, V., Liu, R.,
                        Wang, R., Castro, P.S., Li, Y., Schubert, L., Bellemare, M., Clune, J. and Lehman, J., 2018.
                        arXiv preprint arXiv:1812.07069. </li>
                    <li id="atarifeaturevis"><span class="title">Finding and Visualizing Weaknesses of Deep
                            Reinforcement Learning Agents</span>  <a
                            href="https://arxiv.org/pdf/1904.01318.pdf">[PDF]</a><br>Rupprecht, C., Ibrahim, C. and Pal,
                        C.J., 2019. arXiv preprint arXiv:1904.01318. </li>
                    <li id="caricatures"><span class="title">Caricatures</span> <br>Cammerata, N., Olah, C. and
                        Satyanarayan, A., unpublished. Distill draft. Author list not yet finalized.</li>
                    <li id="adversarialtraining"><span class="title">Towards deep learning models resistant to
                            adversarial attacks</span> <br>Madry, A., Makelov, A., Schmidt, L., Tsipras, D. and Vladu,
                        A., 2017. arXiv preprint arXiv:1706.06083. </li>
                    <li id="featurevisadversarial"><span class="title">Intriguing properties of neural networks</span>
                         <a href="https://arxiv.org/pdf/1312.6199.pdf">[PDF]</a><br>Szegedy, C., Zaremba, W., Sutskever,
                        I., Bruna, J., Erhan, D., Goodfellow, I. and Fergus, R., 2013. arXiv preprint arXiv:1312.6199.
                    </li>
                    <li id="perturbationsaliency"><span class="title">Visualizing and understanding Atari agents</span>
                         <a href="https://arxiv.org/pdf/1711.00138.pdf">[PDF]</a><br>Greydanus, S., Koul, A., Dodge, J.
                        and Fern, A., 2017. arXiv preprint arXiv:1711.00138. </li>
                    <li id="sarfa"><span class="title">Explain Your Move: Understanding Agent Actions Using Specific and
                            Relevant Feature Attribution</span>  <a
                            href="https://nikaashpuri.github.io/sarfa-saliency/">[link]</a><br>Puri, N., Verma, S.,
                        Gupta, P., Kayastha, D., Deshmukh, S., Krishnamurthy, B. and Singh, S., 2019. International
                        Conference on Learning Representations. </li>
                    <li id="rmo"><span class="title">Video Interface: Assuming Multiple Perspectives on a Video Exposes
                            Hidden Structure</span>  <a
                            href="https://rmozone.com/snapshots/2017/10/rmo-at-google/#chew">[link]</a><br>Ochshorn,
                        R.M., 2017. </li>
                    <li id="doubledescent"><span class="title">Reconciling modern machine-learning practice and the
                            classical bias--variance trade-off</span>  <a
                            href="http://www.cs.columbia.edu/~djhsu/papers/biasvariance-pnas.pdf">[PDF]</a><br>Belkin,
                        M., Hsu, D., Ma, S. and Mandal, S., 2019. Proceedings of the National Academy of Sciences, Vol
                        116(32), pp. 15849--15854. National Acad Sciences.</li>
                    <li id="advexfeatures"><span class="title">Adversarial examples are not bugs, they are
                            features</span>  <a href="https://gradientscience.org/adv/">[link]</a><br>Ilyas, A.,
                        Santurkar, S., Tsipras, D., Engstrom, L., Tran, B. and Madry, A., 2019. arXiv preprint
                        arXiv:1905.02175. </li>
                    <li id="advexfeaturesdiscussion"><span class="title">A Discussion of 'Adversarial Examples Are Not
                            Bugs, They Are Features'</span> <br>Engstrom, L., Gilmer, J., Goh, G., Hendrycks, D., Ilyas,
                        A., Madry, A., Nakano, R., Nakkiran, P., Santurkar, S., Tran, B., Tsipras, D. and Wallace, E.,
                        2019. Distill. <a href="https://doi.org/10.23915/distill.00019"
                            style="text-decoration:inherit;">DOI: 10.23915/distill.00019</a></li>
                    <li id="capturetheflag"><span class="title">Human-level performance in 3D multiplayer games with
                            population-based reinforcement learning</span>  <a
                            href="https://deepmind.com/blog/article/capture-the-flag-science">[link]</a><br>Jaderberg,
                        M., Czarnecki, W.M., Dunning, I., Marris, L., Lever, G., Castaneda, A.G., Beattie, C.,
                        Rabinowitz, N.C., Morcos, A.S., Ruderman, A. and others,, 2019. Science, Vol 364(6443), pp.
                        859--865. American Association for the Advancement of Science.</li>
                    <li id="rubik"><span class="title">Solving Rubik's Cube with a Robot Hand</span>  <a
                            href="https://openai.com/blog/solving-rubiks-cube/">[link]</a><br>Akkaya, I., Andrychowicz,
                        M., Chociej, M., Litwin, M., McGrew, B., Petron, A., Paino, A., Plappert, M., Powell, G., Ribas,
                        R. and others,, 2019. arXiv preprint arXiv:1910.07113. </li>
                    <li id="dota"><span class="title">Dota 2 with Large Scale Deep Reinforcement Learning</span>  <a
                            href="https://openai.com/projects/five/">[link]</a><br>Berner, C., Brockman, G., Chan, B.,
                        Cheung, V., Dębiak, P., Dennison, C., Farhi, D., Fischer, Q., Hashme, S., Hesse, C. and others,,
                        2019. arXiv preprint arXiv:1912.06680. </li>
                    <li id="attributionpaths"><span class="title">Does Attribution Make Sense?</span> <br>Olah, C. and
                        Satyanarayan, A., unpublished. Distill draft. Author list not yet finalized.</li>
                    <li id="impala"><span class="title">IMPALA: Scalable distributed deep-RL with importance weighted
                            actor-learner architectures</span>  <a
                            href="https://arxiv.org/pdf/1802.01561.pdf">[PDF]</a><br>Espeholt, L., Soyer, H., Munos, R.,
                        Simonyan, K., Mnih, V., Ward, T., Doron, Y., Firoiu, V., Harley, T., Dunning, I. and others,,
                        2018. arXiv preprint arXiv:1802.01561. </li>
                </ol>
            </d-citation-list>
            <distill-appendix>
                <style>
                    distill-appendix {
                        contain: layout style;
                    }

                    distill-appendix .citation {
                        font-size: 11px;
                        line-height: 15px;
                        border-left: 1px solid rgba(0, 0, 0, 0.1);
                        padding-left: 18px;
                        border: 1px solid rgba(0, 0, 0, 0.1);
                        background: rgba(0, 0, 0, 0.02);
                        padding: 10px 18px;
                        border-radius: 3px;
                        color: rgba(150, 150, 150, 1);
                        overflow: hidden;
                        margin-top: -12px;
                        white-space: pre-wrap;
                        word-wrap: break-word;
                    }

                    distill-appendix>* {
                        grid-column: text;
                    }
                </style>

                <h3 id="updates-and-corrections">Updates and Corrections</h3>
                <p>
                    If you see mistakes or want to suggest changes, please <a
                        href="https://github.com/distillpub/post--understanding-rl-vision/issues/new">create an issue on
                        GitHub</a>. </p>

                <h3 id="reuse">Reuse</h3>
                <p>Diagrams and text are licensed under Creative Commons Attribution <a
                        href="https://creativecommons.org/licenses/by/4.0/">CC-BY 4.0</a> with the <a class="github"
                        href="https://github.com/distillpub/post--understanding-rl-vision">source available on
                        GitHub</a>, unless noted otherwise. The figures that have been reused from other sources don’t
                    fall under this license and can be recognized by a note in their caption: “Figure from …”.</p>

                <h3 id="citation">Citation</h3>
                <p>For attribution in academic contexts, please cite this work as</p>
                <pre class="citation short">Hilton, et al., "Understanding RL Vision", Distill, 2020.</pre>
                <p>BibTeX citation</p>
                <pre class="citation long">@article{hilton2020understanding,
  author = {Hilton, Jacob and Cammarata, Nick and Carter, Shan and Goh, Gabriel and Olah, Chris},
  title = {Understanding RL Vision},
  journal = {Distill},
  year = {2020},
  note = {https://distill.pub/2020/understanding-rl-vision},
  doi = {10.23915/distill.00029}
}</pre>
            </distill-appendix>
        </d-appendix>
    </main>
    <footer>
        <div class="footer__item socials">
            <ul>
                <li>
                    <a href="mailto:abougadre@gmail.com" target="_blank" rel="noopener noreferrer" class="email">
                        <svg aria-hidden="true" focusable="false" data-prefix="far" data-icon="envelope" class=""
                            role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
                            <path fill="currentColor"
                                d="M464 64H48C21.49 64 0 85.49 0 112v288c0 26.51 21.49 48 48 48h416c26.51 0 48-21.49 48-48V112c0-26.51-21.49-48-48-48zm0 48v40.805c-22.422 18.259-58.168 46.651-134.587 106.49-16.841 13.247-50.201 45.072-73.413 44.701-23.208.375-56.579-31.459-73.413-44.701C106.18 199.465 70.425 171.067 48 152.805V112h416zM48 400V214.398c22.914 18.251 55.409 43.862 104.938 82.646 21.857 17.205 60.134 55.186 103.062 54.955 42.717.231 80.509-37.199 103.053-54.947 49.528-38.783 82.032-64.401 104.947-82.653V400H48z"
                                style="--darkreader-inline-fill: currentColor;" data-darkreader-inline-fill=""></path>
                        </svg>
                    </a>
                </li>
                <li>
                    <a href="https://github.com/okimdone/" target="_blank" rel="noopener noreferrer" class="github">
                        <svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="github" class=""
                            role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512">
                            <path fill="currentColor"
                                d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"
                                style="--darkreader-inline-fill: currentColor;" data-darkreader-inline-fill=""></path>
                        </svg>
                    </a>
                </li>
                <li>
                    <a href="https://www.linkedin.com/in/abougadre/" target="_blank" rel="noopener noreferrer"
                        class="linkedin">
                        <svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="linkedin-in" class=""
                            role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512">
                            <path fill="currentColor"
                                d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z"
                                style="--darkreader-inline-fill: currentColor;" data-darkreader-inline-fill=""></path>
                        </svg>
                    </a>
                </li>
                <li>
                    <a href="https://stackoverflow.com/users/9725116/pixel-tek" target="_blank"
                        rel="noopener noreferrer" class="stackoverflow">
                        <svg aria-hidden="true" focusable="false" data-prefix="fab" data-icon="stackoverflow" class=""
                            role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 120 130">
                            <g xmlns="http://www.w3.org/2000/svg" fill="currentColor" fill-rule="evenodd">
                                <polygon fill="#BBBBBB" points="88 80 99 80 99 124 0 124 0 80 11 80 11 113 88 113" />
                                <path fill="currentColor" fill-rule="currentColor"
                                    d="M22.9878906,76.73 L77.0128906,88.085 L79.2838906,77.285 L25.2588906,65.925 L22.9878906,76.73 Z M30.1368906,50.861 L80.1828906,74.169 L84.8448906,64.16 L34.7978906,40.852 L30.1368906,50.861 Z M43.9848906,26.308 L86.4128906,61.639 L93.4788906,53.154 L51.0508906,17.824 L43.9848906,26.308 Z M71.3718906,0.192 L62.5118906,6.782 L95.4598906,51.082 L104.319891,44.493 L71.3718906,0.192 Z M22,102 L77,102 L77,91 L22,91 L22,102 Z" />
                            </g>
                        </svg>
                    </a>
                </li>
            </ul>
        </div>
        <div class="footer__item">
            <p>
                Copyright © 2022 Achraf Bougadre
            </p>
        </div>
    </footer>
</body>

</html>